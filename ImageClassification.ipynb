{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T432IQJgiZeV"
   },
   "source": [
    "# Image Classification using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4HA8ee2lzJ9W"
   },
   "source": [
    "## Problem\n",
    "Given a set of box images, classify whether the box is 'good' or 'bad'.\n",
    "\n",
    "## Objective\n",
    "  1. Classify the box images as 'good' or 'bad'       using Convolutional Neural Networks (CNN).\n",
    "  2. Differentiate each of the CNN architectures and models used\n",
    "  3. Select the best model for the problem based on a set of criteria\n",
    "  \n",
    "## Data\n",
    "There are 379 images of boxes in the data which are sorted by their classification. Out of the 379 images, 186 are tagged as \"NG\" (Not Good) while 187 are tagged as \"OK\" (good condition). \n",
    "\n",
    "Visual inspection of the boxes was performed. We saw that NG box images are boxes in 'bad conditions' e.g. box has been torn, or  the box has holes or tears.On the other hand,'OK' box images are boxes in 'good condition' e.g. neat, no wear and tear, and no holes. \n",
    "\n",
    "We will be splitting the data into test and train datasets in 60-40 ratio: 60% of data goes to training test while 40% goes to test set.\n",
    " \n",
    "## Methodology\n",
    " \n",
    "### Convolutional Neural Networks\n",
    " Convolutional Neural Networks (also called CNN or ConvNets) is an artificial neural network technique that preserves spatial structure which allows it to scale full images well. This characteristic of CNNs enables it to achieve excellent results to computer vision problems compared to regular neural networks.\n",
    " \n",
    "  The Keras module in Python contains several CNN architectures with pre-trained weights from ImageNet which can be used for prediction, fine-tuning, and feature extraction. \n",
    " \n",
    " ### Transfer Learning & ImageNet\n",
    "  \n",
    "  Transfer learning is a machine learning technique where a previously generated model trained on a specific task is reused on a second related task. \n",
    " \n",
    " \n",
    " ImageNet is a large set of annotated photographs which are intended for research and development of methods for computer vision. \n",
    " \n",
    " We will be using Transfer learning through image classification architectures trained using ImageNet, i.e. **VGG16**, **MobileNet**,and **InceptionV3**. We will be selecting one champion model based on accuracy, runtime, error/loss, and usability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZZZNw5fhxrT"
   },
   "source": [
    "## Model Selection\n",
    "\n",
    "Champion model will be selected based on the following criteria:\n",
    "\n",
    "*  **Accuracy** - correctness of predictions \n",
    "*  **Run Time** - length of time the model was trained. Run time is a metric to be considered especially on problems on a limited timeframe. \n",
    "*   **Error/Loss** - indicates how well the model behaves after iteration of optimization\n",
    "*   **Usability**- how will the model be deployed, and how the other criteria/metric affect its deployment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EeJLN_YshxH5"
   },
   "source": [
    "### VGG16\n",
    "\n",
    "VGG16 is a network known for its simplicity. The network utilizes a 3x3 convolutional layer stacked  in increasing depth. Max pooling handles the reduction of the volume size. The '16' in 'VGG16' refers to the number of weight layers in the network. \n",
    "\n",
    "One of the drawbacks of this network is that the network architecture has large weights, making it computationally intensive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1401
    },
    "colab_type": "code",
    "id": "6jYhtRkjlQJi",
    "outputId": "e1d3f47a-0fd7-48c3-e3f7-ec5316b52e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n",
      "Build model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 300, 300, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 300, 300, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 150, 150, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 150, 150, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 150, 150, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 75, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 75, 75, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 75, 75, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 225 images belonging to 2 classes.\n",
      "Found 148 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:90: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:90: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., verbose=2, shuffle=True, steps_per_epoch=30, epochs=10, validation_steps=70)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 770s - loss: 7.6831 - acc: 0.4917 - val_loss: 7.8864 - val_acc: 0.5107\n",
      "Epoch 2/10\n",
      " - 741s - loss: 8.3346 - acc: 0.4829 - val_loss: 7.8864 - val_acc: 0.5107\n",
      "Epoch 3/10\n",
      " - 751s - loss: 7.6561 - acc: 0.5250 - val_loss: 8.3469 - val_acc: 0.4821\n",
      "Epoch 4/10\n",
      " - 741s - loss: 7.6624 - acc: 0.5246 - val_loss: 7.7712 - val_acc: 0.5179\n",
      "Epoch 5/10\n",
      " - 751s - loss: 7.6561 - acc: 0.5250 - val_loss: 7.7712 - val_acc: 0.5179\n",
      "Epoch 6/10\n",
      " - 739s - loss: 8.8590 - acc: 0.4504 - val_loss: 8.0015 - val_acc: 0.5036\n",
      "Epoch 7/10\n",
      " - 750s - loss: 8.7306 - acc: 0.4583 - val_loss: 7.8864 - val_acc: 0.5107\n",
      "Epoch 8/10\n",
      " - 740s - loss: 8.3212 - acc: 0.4837 - val_loss: 7.9439 - val_acc: 0.5071\n",
      "Epoch 9/10\n",
      " - 751s - loss: 7.9247 - acc: 0.5083 - val_loss: 8.0015 - val_acc: 0.5036\n",
      "Epoch 10/10\n",
      " - 739s - loss: 8.1868 - acc: 0.4921 - val_loss: 7.9439 - val_acc: 0.5071\n",
      "7474.430474996567\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "import numpy as np\n",
    "import time\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(45)\n",
    "    nb_class = 2\n",
    "    width, height = 300,300\n",
    "\n",
    "    sn = VGG16(weights='imagenet',include_top=False,input_shape=(width,height,3))\n",
    "    \n",
    "    model=models.Sequential()\n",
    "    model.add(sn)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256,activation='relu'))\n",
    "    model.add(layers.Dense(2,activation='softmax'))\n",
    "    \n",
    "    print('Build model')\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=0.0002, momentum=0.9, nesterov=True)\n",
    "    model.compile(\n",
    "        optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(sn.summary())\n",
    "\n",
    "    # Training\n",
    "    train_data_dir = '/content/drive/My Drive/Assessment//boxes/train'\n",
    "    validation_data_dir = '/content/drive/My Drive/Assessment/boxes/test'\n",
    "    nb_train_samples = 120\n",
    "    nb_validation_samples =70\n",
    "    nb_epoch = 10\n",
    "\n",
    "    #   Generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(width, height),\n",
    "            batch_size=4,\n",
    "            class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            target_size=(width, height),\n",
    "            batch_size=4,\n",
    "            class_mode='categorical')\n",
    "                                     \n",
    "    start=time.time()\n",
    "    model.fit_generator(\n",
    "            train_generator,\n",
    "            samples_per_epoch=nb_train_samples,\n",
    "            nb_epoch=nb_epoch,\n",
    "            validation_data=validation_generator,\n",
    "            nb_val_samples=nb_validation_samples, \n",
    "            verbose=2,\n",
    "            shuffle=True)\n",
    "    end=time.time()\n",
    "    print(end-start)\n",
    "    sn.save_weights('/content/drive/My Drive/Assessment/boxes/weights_VGG16.h5')\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVT6ZozqiLBd"
   },
   "source": [
    "### InceptionV3\n",
    "\n",
    "InceptionV3 is the 3rd variant of the network originally called *GoogLeNet*. The network that is 42 layers deep, which allows it to obtain a lower error rate. The network computes 1x1, 3x3, and 5x5 convolutions with the same module of the network.\n",
    "\n",
    "InceptionV3 has smaller weights and is more efficient than VGGNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12692
    },
    "colab_type": "code",
    "id": "IjW7SCVXqDiS",
    "outputId": "d337a229-04eb-48ed-a5c2-9d9a29a15036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Build model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 149, 149, 32) 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 149, 149, 32) 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 149, 149, 32) 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 147, 147, 32) 9216        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 147, 147, 32) 96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 147, 147, 32) 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 147, 147, 64) 18432       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 147, 147, 64) 192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 147, 147, 64) 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 73, 73, 80)   5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 73, 73, 80)   240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 73, 73, 80)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 71, 71, 192)  138240      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 71, 71, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 71, 71, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 35, 35, 64)   192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 35, 35, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 35, 35, 96)   55296       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 35, 35, 48)   144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 35, 35, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 35, 35, 48)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 35, 35, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 35, 35, 64)   76800       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 35, 35, 96)   82944       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 35, 35, 64)   192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 35, 35, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 35, 35, 96)   288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 35, 35, 32)   96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 35, 35, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 35, 35, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 35, 35, 96)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 35, 35, 32)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_100[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 35, 35, 64)   192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 35, 35, 64)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 35, 35, 96)   55296       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 35, 35, 48)   144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 35, 35, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 35, 35, 48)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 35, 35, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 35, 35, 64)   76800       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 35, 35, 96)   82944       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 35, 35, 64)   192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 35, 35, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 35, 35, 96)   288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 35, 35, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 35, 35, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 35, 35, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 35, 35, 96)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 35, 35, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_107[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 35, 35, 64)   192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 35, 35, 64)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 35, 35, 96)   55296       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 35, 35, 48)   144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 35, 35, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 35, 35, 48)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 35, 35, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 35, 35, 64)   76800       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 35, 35, 96)   82944       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 35, 35, 64)   192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 35, 35, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 35, 35, 96)   288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 35, 35, 64)   192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 35, 35, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 35, 35, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 35, 35, 96)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 35, 35, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_114[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 35, 35, 64)   192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 35, 35, 64)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 35, 35, 96)   55296       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 35, 35, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 35, 35, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 17, 17, 96)   82944       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 17, 17, 384)  1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 17, 17, 96)   288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 17, 17, 384)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 17, 17, 96)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 17, 17, 128)  114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 17, 17, 128)  114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 17, 17, 128)  384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 17, 17, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 17, 17, 128)  114688      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 17, 17, 128)  114688      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 17, 17, 128)  384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 17, 17, 128)  384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 17, 17, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 17, 17, 128)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 17, 17, 192)  172032      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 17, 17, 192)  172032      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 17, 17, 192)  576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 17, 17, 192)  576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 17, 17, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 17, 17, 192)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 17, 17, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 17, 17, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 17, 17, 160)  179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 17, 17, 160)  480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 17, 17, 160)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 17, 17, 160)  179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 17, 17, 160)  480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 17, 17, 160)  480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 17, 17, 160)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 17, 17, 160)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 17, 17, 160)  179200      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 17, 17, 160)  179200      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 17, 17, 160)  480         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 17, 17, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 17, 17, 160)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 17, 17, 160)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 17, 17, 192)  215040      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 17, 17, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 17, 17, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 17, 17, 192)  576         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 17, 17, 192)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 17, 17, 192)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_135[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 17, 17, 160)  480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 17, 17, 160)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 17, 17, 160)  179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 17, 17, 160)  179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 17, 17, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 17, 17, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 17, 17, 160)  179200      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 17, 17, 160)  179200      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 17, 17, 160)  480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 17, 17, 160)  480         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 17, 17, 160)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 17, 17, 160)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 17, 17, 192)  215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 17, 17, 192)  215040      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 17, 17, 192)  576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 17, 17, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 17, 17, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 17, 17, 192)  576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 17, 17, 192)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 17, 17, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 17, 17, 192)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "                                                                 activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 17, 17, 192)  576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 17, 17, 192)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 17, 17, 192)  258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 17, 17, 192)  576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 17, 17, 192)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 17, 17, 192)  258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 17, 17, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 17, 17, 192)  576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 17, 17, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 17, 17, 192)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 17, 17, 192)  258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 17, 17, 192)  258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 17, 17, 192)  576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 17, 17, 192)  576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 17, 17, 192)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 17, 17, 192)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 17, 17, 192)  258048      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 17, 17, 192)  258048      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 17, 17, 192)  576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 17, 17, 192)  576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 17, 17, 192)  576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 17, 17, 192)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 17, 17, 192)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 17, 17, 192)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_155[0][0]             \n",
      "                                                                 activation_158[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 17, 17, 192)  576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 17, 17, 192)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 17, 17, 192)  258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 17, 17, 192)  576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 17, 17, 192)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 17, 17, 192)  258048      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 17, 17, 192)  576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 17, 17, 192)  576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 17, 17, 192)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 17, 17, 192)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 320)    552960      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 192)    331776      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 320)    960         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 192)    576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 320)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 192)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_166[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 8, 8, 448)    1344        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 8, 8, 448)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 8, 8, 384)    1548288     activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 8, 8, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 8, 8, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 8, 8, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 8, 8, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 384)    442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 384)    442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 8, 8, 384)    442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 8, 8, 384)    442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 8, 8, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 8, 8, 384)    1152        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 8, 8, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 8, 8, 384)    1152        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 8, 8, 320)    960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 8, 8, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 8, 8, 384)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 8, 8, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 8, 8, 384)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 8, 8, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 8, 8, 320)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 768)    0           activation_177[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 8, 8, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_171[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 8, 8, 448)    1344        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 8, 8, 448)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 8, 8, 384)    1548288     activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 8, 8, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 8, 8, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 8, 8, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 8, 8, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 8, 8, 384)    442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 8, 8, 384)    442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 8, 8, 384)    442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 8, 8, 384)    442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 8, 8, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 8, 8, 384)    1152        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 8, 8, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 8, 8, 384)    1152        conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 8, 8, 320)    960         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 8, 8, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 8, 8, 384)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 8, 8, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 8, 8, 384)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 8, 8, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 8, 8, 320)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_182[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 768)    0           activation_186[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_180[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 2)            4098        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,806,882\n",
      "Trainable params: 21,772,450\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Found 225 images belonging to 2 classes.\n",
      "Found 148 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., verbose=2, shuffle=True, steps_per_epoch=30, epochs=10, validation_steps=70)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 348s - loss: nan - acc: 0.5000 - val_loss: nan - val_acc: 0.4964\n",
      "Epoch 2/10\n",
      " - 314s - loss: nan - acc: 0.5246 - val_loss: nan - val_acc: 0.4786\n",
      "Epoch 3/10\n",
      " - 318s - loss: nan - acc: 0.5167 - val_loss: nan - val_acc: 0.5036\n",
      "Epoch 4/10\n",
      " - 313s - loss: nan - acc: 0.5079 - val_loss: nan - val_acc: 0.4821\n",
      "Epoch 5/10\n",
      " - 316s - loss: nan - acc: 0.4500 - val_loss: nan - val_acc: 0.5071\n",
      "Epoch 6/10\n",
      " - 313s - loss: nan - acc: 0.5663 - val_loss: nan - val_acc: 0.4857\n",
      "Epoch 7/10\n",
      " - 316s - loss: nan - acc: 0.4750 - val_loss: nan - val_acc: 0.4964\n",
      "Epoch 8/10\n",
      " - 313s - loss: nan - acc: 0.5246 - val_loss: nan - val_acc: 0.4964\n",
      "Epoch 9/10\n",
      " - 316s - loss: nan - acc: 0.5333 - val_loss: nan - val_acc: 0.4964\n",
      "Epoch 10/10\n",
      " - 311s - loss: nan - acc: 0.4495 - val_loss: nan - val_acc: 0.5000\n",
      "3183.31152844429\n"
     ]
    }
   ],
   "source": [
    "#Inception\n",
    "import keras\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(45)\n",
    "    nb_class = 2\n",
    "    width, height = 300,300\n",
    "    sn = keras.applications.inception_v3.InceptionV3(include_top=True,\n",
    "                                                     weights=None,\n",
    "                                                     input_tensor=None, \n",
    "                                                     input_shape=(300,300,3),\n",
    "                                                     pooling=None,classes=2)\n",
    "\n",
    "    \n",
    "    print('Build model')\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=0.0002, momentum=0.9, nesterov=True)\n",
    "    sn.compile(\n",
    "        optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(sn.summary())\n",
    "\n",
    "    # Training\n",
    "    train_data_dir = '/content/drive/My Drive/Assessment/boxes/train'\n",
    "    validation_data_dir = '/content/drive/My Drive/Assessment/boxes/test'\n",
    "    nb_train_samples = 120\n",
    "    nb_validation_samples =70\n",
    "    nb_epoch = 10\n",
    "\n",
    "    #   Generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(width, height),\n",
    "            batch_size=4,\n",
    "            class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            target_size=(width, height),\n",
    "            batch_size=4,\n",
    "            class_mode='categorical')\n",
    "                                         \n",
    "    start=time.time()\n",
    "    sn.fit_generator(\n",
    "            train_generator,\n",
    "            samples_per_epoch=nb_train_samples,\n",
    "            nb_epoch=nb_epoch,\n",
    "            validation_data=validation_generator,\n",
    "            nb_val_samples=nb_validation_samples, \n",
    "            verbose=2,\n",
    "            shuffle=True)\n",
    "    end=time.time()\n",
    "    sn.save_weights('/content/drive/My Drive/Assessment/boxes/weights_inceptionv3.h5')\n",
    "    print(end-start)\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x54HJc8HwpnY"
   },
   "source": [
    "### MobileNET\n",
    "\n",
    "Compared to VGGNet, MobileNet is a small convolutional network. Its lightweight architecture is caused by depthwise convolution, which applies a single filter to each input channel. Pointwise convolution is also performed where a 1x1 convolution is applied to combine outputs of the depthwise convolution. It is a low maintenance network, making it perform faster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4055
    },
    "colab_type": "code",
    "id": "A9cnDxC-u3QX",
    "outputId": "eae3ff0c-9f68-48bd-c026-3501ee1191a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Build model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 2)           2050      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,230,914\n",
      "Trainable params: 3,209,026\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 225 images belonging to 2 classes.\n",
      "Found 148 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., verbose=2, shuffle=True, steps_per_epoch=30, epochs=10, validation_steps=70)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 157s - loss: 1.1088 - acc: 0.5750 - val_loss: 4.4187 - val_acc: 0.4929\n",
      "Epoch 2/10\n",
      " - 142s - loss: 0.7466 - acc: 0.6831 - val_loss: 8.3469 - val_acc: 0.4821\n",
      "Epoch 3/10\n",
      " - 143s - loss: 1.0292 - acc: 0.6583 - val_loss: 7.7712 - val_acc: 0.5179\n",
      "Epoch 4/10\n",
      " - 141s - loss: 1.1383 - acc: 0.7081 - val_loss: 8.2893 - val_acc: 0.4857\n",
      "Epoch 5/10\n",
      " - 143s - loss: 0.9386 - acc: 0.7333 - val_loss: 8.3469 - val_acc: 0.4821\n",
      "Epoch 6/10\n",
      " - 141s - loss: 0.8738 - acc: 0.6914 - val_loss: 6.2838 - val_acc: 0.4964\n",
      "Epoch 7/10\n",
      " - 143s - loss: 0.7273 - acc: 0.7167 - val_loss: 2.4915 - val_acc: 0.5107\n",
      "Epoch 8/10\n",
      " - 141s - loss: 0.7000 - acc: 0.7006 - val_loss: 3.1710 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      " - 143s - loss: 0.7656 - acc: 0.7083 - val_loss: 0.7007 - val_acc: 0.6321\n",
      "Epoch 10/10\n",
      " - 141s - loss: 0.6188 - acc: 0.8090 - val_loss: 0.9489 - val_acc: 0.6286\n",
      "1438.1385519504547\n"
     ]
    }
   ],
   "source": [
    "#mobile NET\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNet\n",
    "import numpy as np\n",
    "import time\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(45)\n",
    "    nb_class = 2\n",
    "    width, height = 224,224\n",
    "\n",
    "    sn=keras.applications.mobilenet.MobileNet(classes=2,weights=None)\n",
    "    print('Build model')\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=0.0002, momentum=0.9, nesterov=True)\n",
    "    sn.compile(\n",
    "        optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(sn.summary())\n",
    "\n",
    "    # Training\n",
    "    train_data_dir = '/content/drive/My Drive/Assessment/boxes/train'\n",
    "    validation_data_dir = '/content/drive/My Drive/Assessment/boxes/test'\n",
    "    nb_train_samples=120\n",
    "    nb_validation_samples=70\n",
    "    nb_epoch=10\n",
    "\n",
    "    #   Generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(width, height),\n",
    "            batch_size=4,\n",
    "            class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            target_size=(width, height),\n",
    "            batch_size=4,\n",
    "            class_mode='categorical')                                       \n",
    "    start=time.time()\n",
    "    sn.fit_generator(\n",
    "            train_generator,\n",
    "            samples_per_epoch=nb_train_samples,\n",
    "            nb_epoch=nb_epoch,\n",
    "            validation_data=validation_generator,\n",
    "            nb_val_samples=nb_validation_samples, \n",
    "            verbose=2,\n",
    "            shuffle=True)\n",
    "    end=time.time()\n",
    "    sn.save_weights('/content/drive/My Drive/Assessment/boxes/weights_mobilenet_10epochs.h5')\n",
    "    print(end-start)\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-O8a6yNIaKE"
   },
   "source": [
    "## Model Selection Summary\n",
    "\n",
    "We will be looking at each of the criteria to determine our champion model. For easier comparison, all three models were ran using the following hyperparameters:\n",
    "*  Learning rate (**0.01** )\n",
    "*  Decay (**0.0002**)\n",
    "*  Nesterov Momentum (**0.9**)\n",
    "*  Batch size (**4**)\n",
    "*  Epochs (**10**)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99IYwQq4gmls"
   },
   "source": [
    "## Accuracy\n",
    "\n",
    "After running 10 epochs, the validation accuracy of the three models are as follows:\n",
    "*   VGG16 (**51%**)\n",
    "*   InceptionV3 (**50%**)\n",
    "*   MobileNet (**63%**)\n",
    "\n",
    "The other two models exhibit stability across 10 epochs. MobileNet was stable for the first few epochs and had a drastic increase in accuracy at the 9th epoch.\n",
    "\n",
    "MobileNet provided the best validation  accuracy at 63%. The model is not as stable as the other two but it can be seen that MobileNet learned better. Another reason is that we are still better off with an unstable MobileNet model than models whose accuracy is not as different as that of a random guess.\n",
    "\n",
    "\n",
    "**Winner: MobileNet**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhwB-cu6gHAX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "WB5m8sa8Xrlv",
    "outputId": "7cf99de8-3670-4bef-f7d9-7f7255a258e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8a639cb4e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd4VMX6xz9vQiB0JAQFQlVAKSG0\nINJtICDIFcHQRPSCXhEbIhYUsN3rj2tHvV5FQZFyAREFBRSCgixVQAJSxCChG2qAAEne3x+zCZu+\nGzbZTTKf5znPnnNmzsz3nN2d98w7TVQVi8VisRQ/AnwtwGKxWCy+wRoAi8ViKaZYA2CxWCzFFGsA\nLBaLpZhiDYDFYrEUU6wBsFgslmKKNQBFHBGpIyIqIiWcx9+KyD3uxM1DXs+IyEeXo7e4U5yfoYhE\ni8j9vtZRnLAGwM8Rke9EZGIW53uLyCFPC2tVvU1Vp3pBV2cRicuQ9iuqmm9/YGeeKiJP5VcevuZy\nnqGIdBGR5SJyUkRiswiv4ww/KyK/icjNOaT1qYhcEJEEl21zXnRZ/BdrAPyfqcAgEZEM5wcD01U1\nyQeafMU9wDFgSEFnnNdaUQFzBpgCPJlN+AzgFyAEeBaYIyKhOaT3mqqWc9maeVeuxddYA+D/zMf8\nYTuknhCRK4CewDTncQ8R+UVETonIPhEZn11irtVsEQkUkUki8peI7AF6ZIh7r4hsF5HTIrJHREY4\nz5cFvgWqu7wdVheR8SLyucv1vUQkRkROOPO9ziUsVkRGi8gW5xvrLBEJzkF3WaAv8BBQX0RaZQhv\nLyI/O/PaJyJDnedLi8i/RWSvM5+VznOZajBOTTc798eLyBwR+VxETgFDRSRSRFY78zgoIu+KSEmX\n6xuLyFIROSYih53unKucb9whLvFaiMhREQnK4j7TnqGLS+4eEfnT+T09m90zUtW1qvoZsCeLdBsA\nLYAXVPWcqs4FfgXuzC697HDRNVxEDjifxWiX8FIi8qYz7IBzv5RLeG8R2eT8vf4uIt1ckq8tIquc\nv7klIlLFeU2w87uIdz7/dSJypafaLemxBsDPUdVzwGzSv/X2A35T1dQq+RlneCVMIf6giNzhRvJ/\nxxiS5kArTAHryhFneAXgXuANEWmhqmeA24ADLm+HB1wvdBY4M4BHgVBgEfC1a4HpvI9uQF0gHBia\ng9a/AQnA/4DFmNpAal61MQbpHWdeEcAmZ/AkoCVwA1AZGAOk5PRQXOgNzME81+lAMvAYUAVoC9wE\n/MOpoTzwPfAdUB24BvhBVQ8B0c57TWUwMFNVL7qpoz3Q0Jnf866G1AMaA3tU9bTLuc3O83mlC1Af\nuBV4ysWl9CxwPeZ7aAZEAs8BiEgk5sXlScxz7QjEuqQ5APNbqwqUBFINyz1ARaAm5oXoAeDcZWi3\nYA1AYWEq0NflDXmI8xwAqhqtqr+qaoqqbsEUvJ3cSLcf8Kaq7lPVY8CrroGqulBVf1fDCmAJLjWR\nXOgPLFTVpc6CbhJQGlMQp/K2qh5w5v01psDIjnuAWaqaDHwB3O3yBj0A+F5VZ6jqRVWNV9VNIhIA\nDAMeUdX9qpqsqj+r6nk372G1qs53PtdzqrpBVR2qmqSqscB/uPScewKHVPXfqpqoqqdVdY0zbCow\nCEytC4gCPnNTA8AEZ/6bMYV2Xlwx5YCTGc6dBMrncM1o59t26pax7WiCqp5R1V+BTzD3BTAQmKiq\nR1T1KDABY/QA7gOmOH8XKc7v5TeXND9R1Z0uLz6pv4mLmIL/Guf3uEFVT3lw/5YssAagEKCqK4G/\ngDtE5GrMG9UXqeEi0kZM495RETmJeTuq4kbS1YF9Lsd7XQNF5DYRcThdGieA7m6mm5p2WnqqmuLM\nq4ZLnEMu+2cxhVQmRKQm5m1zuvPUV0Awl1xWNYHfs7i0ijNeVmHu4PpsEJEGIvKNmMb3U8ArXHoe\n2WlI1dtIROoCtwAnVXWtBzrcek65kICpyblSATidRdxUJqlqJZctY++xjL+d6s79dN99hrCcnhNk\nf6+fYWp+M51updeycqFZPMMagMLDNMyb/yBgsaoedgn7AlgA1FTVisAHQMZG46w4iPlDplIrdcfp\ns52LeXO/UlUrYdw4qenmNo3sAaC2S3rizGu/G7oyMhjzW/1aRA5hfNzBXHID7QOuzuK6v4DEbMLO\nAGVc9AVi3EeuZLzH94HfgPqqWgF4hkvPYx9QLyvxqpqIeZsd5LwXT97+vUUMUM/pqkqlmfN8Xsn4\n20l1A6b77jOEZfdd5YizZjdBVRthapE98UFngKKGNQCFh2nAzRi/fcaqeHngmKomOn2sA9xMczYw\nSkTCxDQsj3UJKwmUAo4CSSJyG8bXm8phIEREKuaQdg8Rucn5pvYEcB742U1trtyDcSNEuGx3At2d\njavTgZtFpJ+IlBCREBGJcNY6pgCvi2mkDhSRtk7jthMIFtOAHoTxUZfKKnMXygOngAQRuRZ40CXs\nG6CaiDzqbAQtLyJtXMKnYdo4epFPBkBEApxuwiBzKMGpbS6quhPTLvKC83wfTLvL3MvIcpyIlBGR\nxhi//Szn+RnAcyIS6mzEfR5I7RzwMXCv83cRICI1nM8yt3vrIiJNnYb6FMYl5G5bjiUbrAEoJDh9\nzj8DZTFv+678A5goIqcxf7bZbib7X0y1ejOwEZjnkt9pYJQzreMYo7LAJfw3zB99j9M/XN0lXVR1\nB+aN9x3Mm/jtwO2qesFNbQCIyPWYt8nJqnrIZVsA7AaiVPVPjHvqCUw30U1c8pOPxvR2WecM+xcQ\noKonMc/tI0yt5AyQrldQFox2PofTmGeXWuClPq9bnPd5CNiFcVulhq/CFFgbVTWdq82LdMQ0jC7C\nvHWfw7TbpHI3prH/OPBPoK/TR58dYyT9OIC/MoSvwHwHP2DcRal5vQSsB7Zgnv1G5zmcrq97gTcw\nbRArSF9byI6rMA3yp4Dtzut8UZMqUohdEMZiKRhEZBnwhaoW6pG+IlIH+AMIKmbjUIochWFwi8VS\n6BGR1ph++L19rcViScUtF5CIdBORHSKyW0TGZhOnn4hsEzPw54sMYRVEJE5E3vWGaIulMOHsPvk9\n8GiGfvgWi0/J1QXkbHTZifFvxmF8qVGqus0lTn2Mr/hGVT0uIlVV9YhL+FuYHhbHVHWk92/DYrFY\nLJ7iTg0gEtitqnucDXgzyVyN/Tumke44QIbCvyVwJekboywWi8XiY9xpA6hB+gEfcUCbDHEaAIjI\nKiAQGK+q3zlHYv4b0xskp5kHhwPDAYKDg1vWqlUru6g+IyUlhYAA/+o0ZTW5h9XkPv6oy2pyj507\nd/6lqjlN7pcJbzUCl8DMCdIZCAN+FJGmmIJ/karGSabJLC+hqh8CHwI0bNhQd+zY4SVZ3iM6OprO\nnTv7WkY6rCb3sJrcxx91WU3uISIedy92xwDsJ/2IvzAyj+aMA9Y453z5Q0R2YgxCW6CDiPwDM6S7\npIgkqGqWDckWi8ViKTjcqcOsw0y/W9c5qvBuMg9Emo95+8c58q8BZubBgapaS1XrYAbRTLOFv8Vi\nsfgHuRoA50CPkZgRo9uB2aoaIyITRaSXM9piIF5EtgHLgSdVNT6/RFssFovl8nGrDUBVF2GGl7ue\ne95lX4HHnVt2aXwKfJoXkRcvXiQuLo7ExMS8XO4VKlasyPbt232Wf1YUhKbg4GDCwsIICrITL1os\nRY1CMRI4Li6O8uXLU6dOHXJqTM5PTp8+TfnyOU2dXvDktyZVJT4+nri4OOrWrZtv+VgsFt/gX/2Y\nsiExMZGQkBCfFf7FFREhJCTEpzUvi8WSfxQKAwDYwt9H2OdusRRdCoULyGKxWPyFdetg5syaHD4M\ntWub7corwc/GhbmFNQAeICIMHDiQzz83a1skJSVRrVo12rRpwzfffON2OnXq1GH9+vVUqZL96oru\nxLFYLAXPqFHgcFzNf/5z6VypUlCz5iWDkHELCwN/7EdhDYAHlC1blq1bt3Lu3DlKly7N0qVLqVGj\nRu4XWiyWIsH587BxI/TpE8eECWHs3UumbdEiOHQo/XUBAVC9evYGonZtKFMm6zzzE2sAPKR79+4s\nXLiQvn37MmPGDKKiovjpp58AOHbsGMOGDWPPnj2UKVOGDz/8kPDwcOLj44mKimL//v20bdsW1xlY\nP//8c95++20uXLhAmzZteO+99wgMDPTV7VkslhzYtAkuXICIiBM0bRpG06ZZx0tMhH37MhuHvXvh\n559h9mxIyrCUTpUqWRuGOnXMZ6VK4O0mOWsAPOTuu+9m4sSJ9OzZky1btjBs2LA0A/DCCy/QvHlz\n5s+fz7JlyxgyZAibNm1iwoQJtG/fnueff56FCxfy8ccfA7B9+3ZmzZrFqlWrCAoK4h//+AfTp09n\nyBC71rXF4o84HOazUaNTOcYLDob69c2WFcnJcOBA1gZi2zb49ls4dy79NeXL51yDyAvWAHhIeHg4\nsbGxzJgxg+7du6cLW7lyJXPnmjW2b7zxRuLj4zl16hQ//vgj8+aZ5XZ79OjBFVdcAcAPP/zAhg0b\naN26NQDnzp2jatWqBXg3FovFExwO48+vUsWjpa0zERho2gxq1oT27TOHq8Jff2VtIFJrEcePX5YE\nwBqAPNGrVy9Gjx5NdHQ08fF5n/FCVbnnnnt49dVXvajOYrHkFw4HXH99/ucjAqGhZmvVKus4p07B\nn39eMgoPPeR5PoWw45LvGTZsGC+88AJNMzgAO3TowPTp0wEzXWyVKlWoUKECHTt25IsvzCqZ3377\nLcedpvumm25izpw5HDli1s85duwYe/d6PKOrxWIpAA4dgtjYgjEA7lChAjRpAj16wD/+kbc0bA0g\nD4SFhTFq1KhM58ePH8+wYcMIDw+nTJkyTJ06FTBtA1FRUTRu3JgbbriB1AVvGjVqxEsvvcStt95K\nSkoKQUFBTJ48mdp5dehZLJZ8Y80a83n99XDxom+1eAtrADwgISEh07nOnTunLQxRuXJl5s+fnylO\nSEgIS5ZkvSJm//796d+/f6bzsbGxl6XVYrF4F4cDSpSAFi0uGYPCjnUBWSwWixs4HBARAaVL+1qJ\n97AGwGKxWHIhKclMAeEv/n9vYQ2AxWKx5EJMDJw5Yw2AxWKxFDtSB4AVSwMgIt1EZIeI7BaRLNf0\nFZF+IrJNRGJE5AvnuQgRWe08t0VEMrd2WiwWi5/jcJipGurV87US75JrLyARCQQmA7cAccA6EVmg\nqttc4tQHngbaqepxEUkdznoWGKKqu0SkOrBBRBar6gmv34nFYrHkE6kDwIra8hju1AAigd2qukdV\nLwAzgd4Z4vwdmKyqxwFU9Yjzc6eq7nLuHwCOAKHeEl+QVKtWrcDyeuWVV9Id33DDDXlKZ8KECTz9\n9NPpzm3atInrrrsOgG7dutGsWTMaN27MAw88QHJyct4EWyxFmOPH4bffip77B0BcZ6bMMoJIX6Cb\nqt7vPB4MtFHVkS5x5gM7gXZAIDBeVb/LkE4kMBVorKopGcKGA8MBQkNDW86ePTudhooVK3LNNdfk\n6Qa9RbVq1Th48KBf5ZWcnJzjzKG7du3izjvvZMuWLWnnXnjhBUqXLs3YsWM5deoUFSpUQFUZPHgw\nd9xxB3379s2Uzu7duzl58qRb2hMSEihXrpxbcQsKq8l9/FGXrzWtXXsFTz3VjEmTNtGy5Qm/0JQV\nXbp02aCq2UwckQ2qmuMG9AU+cjkeDLybIc43wJdAEFAX2AdUcgmvBuwArs8tvwYNGmhGtm3blulc\nQVO2bFlVVV2+fLl26tRJ77zzTm3YsKEOGDBAU1JSVFV17dq12rZtWw0PD9fWrVvrqVOnNCkpSUeP\nHq2tWrXSpk2b6gcffJCWTocOHbR79+7aoEEDHTFihCYnJ+tTTz2lAQEB2qxZMx0wYEC6vFNSUnT0\n6NHauHFjbdKkiX7yySe5amrRooU6HI60+6hbt67u3Lkz3b1duHBBe/bsqTNnzszy3j15/suXL3c7\nbkFhNbmPP+rytabx41VFVE+evHTO15qyAlivuZSvGTd3RgLvB2q6HIc5z7kSB6xR1YvAHyKyE6iP\naS+oACwEnlVVh0fWKSsefdRMyu1NIiLgzTfdjv7LL78QExND9erVadeuHatWrSIyMpL+/fsza9Ys\nWrduzalTpyhdujQff/wxFStWZN26dZw/f5527dpx6623ArB27Vq2bdtG7dq16datG/PmzeOf//wn\n7777LpuyuMd58+axadMmNm/ezF9//UWrVq3o2rVrtprat29PVFQUM2fOpE2bNjgcDipXrkx9lzlq\nu3btytq1a7ntttuyfPu3WIo7Dgc0bmzm3ilquNMGsA6oLyJ1RaQkcDewIEOc+UBnABGpAjQA9jjj\nfwlMU9U5XlPtYyIjIwkLCyMgIICIiAhiY2PZsWMH1apVS5vauUKFCpQoUYIlS5Ywbdo0IiIiaNOm\nDfHx8ezatSstnXr16hEYGEhUVBQrV67MMd+VK1cSFRVFYGAgV155Je3atWPdunXZagIz1cScOXNI\nSUlh5syZREVFpUtz8eLFHDx4kPPnz7Ns2TIvPymLpXCTkmKmfSiK/n9woxeQqiaJyEhgMca/P0VV\nY0RkIqbKscAZdquIbAOSgSdVNV5EBgEdgRARGepMcqiq5v0V3oM39fyiVKlSafuBgYEkZVzaxwVV\n5Z133kl7U08lOjoaydClIOOxNzTVrFmTunXrsmLFCubOncvq1aszXRscHEzv3r356quvuOWWW/Ks\nwWIpauzaZRqBi6oBcGscgKouUtUGqnq1qr7sPPe8s/DH6YJ6XFUbqWpTVZ3pPP+5qgapaoTL5mX/\njX/QsGFDDh48mPZGfvr0aZKSkujatSvvv/8+F53TB+7cuZMzZ84AxgX0xx9/kJKSwqxZs2jvXBki\nKCgoLb4rHTp0YNasWSQnJ3P06FF+/vlnIiMjc9UWFRXFY489Rr169QgLCwNMI1ZqQ3NSUhILFy7k\n2muvvfwHYbEUIVxnAC2K2JHAXqJkyZLMmjWLhx9+mGbNmnHLLbeQmJjI/fffT6NGjWjRogVNmjRh\nxIgRaW/nrVu3ZuTIkVx33XXUrVuXPn36ADB8+HDCw8MZOHBgujz69OlDeHg4zZo148Ybb2TixIlc\nddVVuWq76667iImJSef+OXPmDL169SI8PJyIiAiqVq3KAw884MUnYrEUfhwO4/t39pwuenjaapzf\nm7/2Ajp16pRX01u+fLn26NHjstLwtqbssL2AvI8/alL1T12+1NS8uerNN2c+74/PiTz0ArI1AIvF\nYsmCM2dgy5ai6/4BuyCMz3BdSMZisfgfGzZAcnLRNgC2BmCxWCxZkDoDaJs2vtWRn1gDYLFYLFng\ncMA115hZQIsq1gBYLBZLBlRh9eqi7f4BawAsFoslE/v2waFD1gBYnFSoUIFBgwalHSclJREaGkrP\nnj1zvG78+PFMmjQp0/kDBw6kzb0THR2dazqpI4e//vrrtHN33XUX0dHROV736aefcuDAgRzjWCyW\n9BTVFcAyYg2Am5QtW5atW7dy7tw5AJYuXUqNGjXynF716tWZM8ez6ZHCwsJ4+eWXPbrGGgCLxXMc\nDggOhvBwXyvJX6wB8IDu3buzcOFCAGbMmJFuZO2xY8e44447CA8P5/rrr083B//mzZtp27Yt9evX\n57///S8AsbGxNGnSJFMeZ86cYdiwYURGRtK8eXO++uqrtLBmzZpRsWJFli5dmum6DRs20KlTJ1q2\nbEnXrl05ePAgc+bMYf369QwcOJCIiIg042WxWHLG4YBWrSAoyNdK8pdCNw7Al7NB33333UycOJGe\nPXuyZcsWhg0bxk8//QSYhVaaN2/O/PnzWbZsGUOGDEmb0nnLli04HA7OnDlD8+bN6dGjR7Z5vPzy\ny9x4441MmTKFEydOEBkZyc0335wW/uyzzzJu3Lh0k7ZdvHiRhx9+mK+++orQ0FBmzZrFs88+y5Qp\nU3j33XeZNGkSrVp5tk6ExVJcOX8eNm6Ehx/2tZL8p9AZAF8SHh5ObGwsM2bMoHv37unCVq5cydy5\ncwG48cYbiY+P59SpUwD07t2b0qVLU7p0abp06cLatWuJiIjIMo8lS5awYMGCtHaDxMRE/vzzz7Tw\njh07puWXyo4dO9i6dWuaUUhOTi7QJSwtlqLE5s3GCBR1/z8UQgPg69mge/XqxejRo4mOjiY+Pt6t\nazyZ9llVmTt3Lg0bNkx3/vDhw2n7zz77LC+99FK6axo3bpzlVM8Wi8UziksDMNg2AI8ZNmwYL7zw\nAk2bNk13vkOHDkyfPh0wPXaqVKlCBecSQl999RWJiYnEx8cTHR2dtmhMVnTt2pV33nkndSlNfvnl\nl0xxbr31Vo4fP05MTAxgpqI+evRomgG4ePFiWlj58uU5ffr0Zd61xVJ8cDggLAwuo49HocEaAA8J\nCwtj1KhRmc6PHz+eDRs2EB4eztixY5k6dWpaWHh4OF26dOH6669n3LhxVK9ePdv0x40bx8WLFwkP\nD6dx48aMGzcuy3jPPvsscXFxgJmKes6cOTz11FM0a9aMiIgIfv75ZwCGDh3KAw88YBuBLRY3cTiK\nx9s/4N500EA3zKLuu4Gx2cTpB2wDYoAvXM7fA+xybvfklldxmQ7aG9jpoN3DanIff9RVkJoOHVIF\n1UmTco7nj8+J/FgUXkQCgcnALZjF39eJyAJV3eYSpz7wNNBOVY+LSFXn+crAC0ArQIENzmuPX77p\nslgsFu9S1FcAy4g7LqBIYLeq7lHVC8BMoHeGOH8HJqcW7Kp6xHm+K7BUVY85w5ZiahMWi8Xidzgc\nUKIEtGjhayUFgzsGoAawz+U4znnOlQZAAxFZJSIOEenmwbUWi8XiFzgcZlxQ6dK+VlIweKsbaAmg\nPtAZCAN+FJGmOV7hgogMB4YDhIaGZprfpmLFij7vyZKcnOxzDRkpKE2JiYm5zjmUSkJCgttxCwqr\nyX38UVdBaUpOhtWrO3DbbQeJjt7tF5ryG3cMwH6gpstxmPOcK3HAGlW9CPwhIjsxBmE/xii4Xhud\nMQNV/RD4EKBhw4aacaWs7du3U758eTek5h+nT5/2uYaMFJSm4OBgmjdv7lbc6Ohov1vpzGpyH3/U\nVVCatmyBxES4884wOncO8wtN+Y07LqB1QH0RqSsiJYG7gQUZ4szHWdCLSBWMS2gPsBi4VUSuEJEr\ngFud5ywWi8WvKE4DwFLJ1QCoahIwElNwbwdmq2qMiEwUkV7OaIuBeBHZBiwHnlTVeFU9BryIMSLr\ngInOc4WOHj16sHhxetv15ptv8uCDD7Jr1y569uzJ1VdfTcuWLenSpQs//vhjWrzvvvuOyMhIrr32\nWiIiIujfv3/a9A7/+9//aNy4MQEBAaxfvz5d+lu2bKFt27Y0btyYpk2bkpiYmP83arEUUxwOs/pX\nvXq+VlJwuNUGoKqLgEUZzj3vsq/A484t47VTgCmXJ9P39O3bl5kzZ9K1a9e0czNnzuS1116jR48e\nTJo0iV69jD3cunUr69evp2PHjmzdupWHH36YBQsWcN111wGwYMECYmNjqVWrFk2aNGHevHmMGDEi\nXX5JSUkMGjSIzz77jGbNmhEfH09QUZ+a0GLxIakDwHKYqaXIUejmAvIVvXv35qWXXuLChQuULFmS\n2NhYDhw4wK5du2jbtm1a4Q/QpEmTtKme//Wvf/HMM8+kFf5Auriu511ZsmQJ4eHhNGvWDICQkJD8\nuC2LxQKcOAHbt8PAgb5WUrAUOgPw6HePsumQd+eDjrgqgje75TzLXOXKlYmMjOTbb7+ld+/ezJw5\nk379+hETE0OLHDoNx8TEMHr0aI817dy5ExGha9euHD16lLvvvpsxY8Z4nI7FYsmdtWvNZ3Hy/4Od\nC8gjoqKimDlzJmDcP64LwqTSp08fmjRpwt/+9rdMYfHx8URERNCgQYMsl4l0JSkpiZUrVzJ9+nRW\nrlzJl19+yQ8//OCdG7FYLOlwOIzrJ4d5Goskha4GkNuben7Su3dvHnvsMTZu3MjZs2dp2bIlmzZt\nStfg++WXX7J+/fq0t/7GjRuzceNGmjVrRkhICJs2bWLSpEkkJCTkmFdYWBgdO3akSpUqgFmNbOPG\njdx00035d4MWSzHF4YDGjcE5gW+xwdYAPKBcuXJ06dKFYcOGpb39DxgwgFWrVrFgwaWesWfPnk3b\nHzNmDC+//DLbt2/PMjw7unbtyq+//srZs2dJSkpixYoVNGrUyIt3Y7FYAFSL2QygLlgD4CFRUVFs\n3rw5zQCULl2ab775hg8++IB69erRtm1bXnrpJZ577jkAmjZtyltvvcWQIUNo2LAh7dq1Y/v27QwY\nMAAwNYawsDBWr15Njx490noZXXHFFTz++OO0bt2aiIgIWrRokeNSkhaLJW/s2gXHjxdPA1DoXEC+\n5o477khbrCWVa6+9lkWLFmVzhRlDkF3h3adPH/r06ZNl2KBBgxg0aFDexVosllwpjgPAUrE1AIvF\nUqxxOIzvP5se2UUaawAsFkuxxuGAyEgIKIalYaG55YxuF0vBYJ+7pShz5oyZBK44un+gkBiA4OBg\n4uPjbWFUwKgq8fHxBAcH+1qKxZIvbNhgpoEurgagUDQCh4WFERcXx9GjR32mITEx0e8KwoLQFBwc\nTFhYzlPjWiyFldQG4MhI3+rwFYXCAAQFBVG3bl2faoiOjnZ7TvyCwh81WSyFCYcDrr4aQkN9rcQ3\nFAoXkMVisXgbVVi9uvi6f8AaAIvFUkzZtw8OHbIGwGKxWIodxXkAWCrWAFgslmKJwwHBwRAe7msl\nvsMtAyAi3URkh4jsFpGxWYQPFZGjIrLJud3vEvaaiMSIyHYReVukOK23Y7FY/BWHA1q2hJIlfa3E\nd+RqAEQkEJgM3AY0AqJEJKtpKWepaoRz+8h57Q1AOyAcaAK0Bjp5S7zFYrHkhfPnYePG4u3+Afdq\nAJHAblXdo6oXgJlAbzfTVyAYKAmUAoKAw3kRarFYLN5i82ZjBIq7AXBnHEANYJ/LcRzQJot4d4pI\nR2An8Jiq7lPV1SKyHDgICPCuqm7PeKGIDAeGA4SGhhIdHe3ZXRQACQkJfqfLanIPq8l9/FFXfmia\nO7cGUB/V1URHn/cLTT5BVXOCKzIGAAAgAElEQVTcgL7ARy7HgzEFuWucEKCUc38EsMy5fw2wECjn\n3FYDHXLKr0GDBuqPLF++3NcSMmE1uYfV5D7+qCs/NEVFqdaokffr/fE5Aes1l/I84+aOC2g/UNPl\nOMx5ztWIxKtqqhn9CGjp3O8DOFQ1QVUTgG+Btu6bJ4vFYvE+xXUFsIy4YwDWAfVFpK6IlATuBha4\nRhCRai6HvYBUN8+fQCcRKSEiQZgG4EwuIIvFYikoDh+GP/6wBgDcaANQ1SQRGQksBgKBKaoaIyIT\nMVWOBcAoEekFJAHHgKHOy+cANwK/YhqEv1PVr71/GxaLxeIea9aYT2sA3JwMTlUXAYsynHveZf9p\n4OksrkvGtAlYLBaLX7BmDZQoAS1a+FqJ77EjgS0WS7HC4YBmzaBMGV8r8T3WAFgslmJDcjKsXWvd\nP6lYA2CxWIoN27ZBQoI1AKlYA2CxWIoNdgbQ9FgDYLFYig0OB4SEmFXALNYAWCyWYkTqADA7J7HB\nGgCLxVIsOHHCtAFY988lrAGwWCzFgnXrzKc1AJewBsBisRQLHA7j+mnd2tdK/AdrACwWS7HA4YBG\njaBiRV8r8R+sAbBYLEUeVTsDaFZYA2CxWIo8u3fDsWPWAGTEGgCLxVLksQPAssYaAIvFUuRxOKB8\nebjuOl8r8S+sAbBYLEUehwMiIyEw0NdK/AtrACwWS5Hm7FnYvNm6f7LCGgCLxVKk2bDBTANtDUBm\n3DIAItJNRHaIyG4RGZtF+FAROSoim5zb/S5htURkiYhsF5FtIlLHe/ItFoslZ1IbgNu08a0OfyTX\nJSFFJBCYDNwCxAHrRGSBqm7LEHWWqo7MIolpwMuqulREygEplyvaYrFY3MXhMLN/hob6Won/4U4N\nIBLYrap7VPUCMBPo7U7iItIIKKGqSwFUNUFVz+ZZrcVisXiAKqxebd0/2eHOovA1gH0ux3FAVpWp\nO0WkI7ATeExV9wENgBMiMg+oC3wPjHUuFp+GiAwHhgOEhoYSHR3t6X3kOwkJCX6ny2pyD6vJffxR\n1+VoOnKkFAcPtiUkZBfR0fv9QpNfoao5bkBf4COX48HAuxnihAClnPsjgGUu154E6mGMzVzgvpzy\na9Cggfojy5cv97WETFhN7mE1uY8/6rocTbNnq4LqunXe06Pqn88JWK+5lOcZN3dcQPuBmi7HYc5z\nrkYkXlXPOw8/Alo69+OATWrcR0nAfKCF++bJYrFY8o7DAcHBEB7uayX+iTsGYB1QX0TqikhJ4G5g\ngWsEEanmctgL2O5ybSURSW1+uRHI2HhssVgs+YLDAS1bQsmSvlbin+RqAJxv7iOBxZiCfbaqxojI\nRBHp5Yw2SkRiRGQzMAoY6rw2GRgN/CAivwIC/Nf7t2GxWCzpuXDBjAGwDcDZ404jMKq6CFiU4dzz\nLvtPA09nc+1SwFbALBZLgbJ5M5w/bw1ATtiRwBaLpUhiZwDNHWsALBZLkcThgBo1ICzM10r8F2sA\nLBZLkcSuAJY71gBYLJYix5EjsGePNQC5YQ2AxWIpcqxZYz6tAcgZawAsFkuRw+GAEiWghR12miPW\nAFgsliKHwwHNmkGZMr5W4t9YA2CxWIoUycmwdq11/7iDNQAWi6VIsW0bJCRYA+AO1gBYLJYihR0A\n5j7WAFgsliKFwwEhIWYVMEvOWANgsViKFKkDwER8rcT/sQbAYrEUGU6cMG0AdgF497AGwGKxFBnW\nrTOf1v/vHtYAWCyWIoPDYVw/kZG+VlI4sAbAYrEUGRwOuO46qFjR10oKB9YAWCyWIoGqnQHUU9wy\nACLSTUR2iMhuERmbRfhQETkqIpuc2/0ZwiuISJyIvOst4RaLxeLK7t1w7Jg1AJ6Q65KQIhIITAZu\nAeKAdSKyQFUzLu4+S1VHZpPMi8CPl6XUYrFYcsAOAPMcd2oAkcBuVd2jqheAmUBvdzMQkZbAlcCS\nvEm0WCyW3HE4oFw5aNTI10oKD6KqOUcQ6Qt0U9X7nceDgTaub/siMhR4FTgK7AQeU9V9IhIALAMG\nATcDrbKqJYjIcGA4QGhoaMvZs2d74da8S0JCAuXKlfO1jHRYTe5hNbmPP+pyV9Pw4S0pVy6J11/f\n7DeaCpIuXbpsUNVWHl2kqjluQF/gI5fjwcC7GeKEAKWc+yOAZc79kcAY5/7QjNdltTVo0ED9keXL\nl/taQiasJvewmtzHH3W5o+nMGdXAQNVnnsl/Par++ZyA9ZpL+Zpxy7UNANgP1HQ5DnOeczUi8S6H\nHwGvOffbAh1E5B9AOaCkiCSoaqaGZIvFYskrGzaYaaCt/98z3DEA64D6IlIXU/DfDQxwjSAi1VT1\noPOwF7AdQFUHusQZinEB2cLfYrF4ldQGYDsFhGfkagBUNUlERgKLgUBgiqrGiMhETJVjATBKRHoB\nScAxjLvHYrFYCgSHA+rVg6pVfa2kcOFODQBVXQQsynDueZf9p4Gnc0njU+BTjxVaLBZLLqxZA506\n+VpF4cOOBLZYLIWauDjYv9/6//OCNQAWi6VQYweA5R1rACwWS6HG4YBSpaBZM18rKXxYA2CxWAo1\nDge0bAklS/paSeHDGgCLxVJouXDBjAGw7p+8YQ2AxWIptGzZAomJ1gDkFWsALBZLocU2AF8e1gBY\nLJZCi8MB1atDWJivlRROrAGwWCyFltQVwER8raRwYg2AxWIplBw9Cr//bt0/l4M1ABaLpVCyZo35\ntAYg71gDYLFYCiUOBwQGmjEAlrxhDYDFYimUOBxm9G+ZMr5WUnixBsBisRQ6kpNh7Vrr/rlcrAGw\nWCyFju3b4fRpawAuF2sALBZLocMOAPMObhkAEekmIjtEZLeIZFrSUUSGishREdnk3O53no8QkdUi\nEiMiW0Skv7dvwGKxFD8cDqhcGa65xtdKCje5rggmIoHAZOAWIA5YJyILVHVbhqizVHVkhnNngSGq\nuktEqgMbRGSxqp7whniLxVI8sQPAvIM7NYBIYLeq7lHVC8BMoLc7iavqTlXd5dw/ABwBQvMq1mKx\nWE6ehG3brPvHG7hjAGoA+1yO45znMnKn080zR0RqZgwUkUigJPB7npRaLBYLsG4dqFoD4A1EVXOO\nINIX6KaqqX79wUAbV3ePiIQACap6XkRGAP1V9UaX8GpANHCPqjqyyGM4MBwgNDS05ezZsy/7xrxN\nQkIC5cqV87WMdFhN7mE1uY8/6sqo6bPPavPJJ3VYsGAl5col+4Umf6BLly4bVLWVJ9e4YwDaAuNV\ntavz+GkAVX01m/iBwDFVreg8roAp/F9R1Tm5CWrYsKHu2LHDk3soEKKjo+ncubOvZaSxfDkcOOBg\n4ED/eQ2KORLDe0ve45qr/atl7q8//+L5O5+nVIlSvpaShr/9nlLxR10ZNfXsCX/8ATEx/qPJHxAR\njw1Aro3AwDqgvojUBfYDdwMDMmRcTVUPOg97Adud50sCXwLT3Cn8Le7x7bfQowdUqtSCG26AunV9\nrQh2H9tN+0/acyLxhF86+aa9M42x7cZyX4v7CC4R7Gs5ljyiahqAe7vVCmnJjVwNgKomichIYDEQ\nCExR1RgRmQisV9UFwCgR6QUkAceAoc7L+wEdgRARST03VFU3efc2ig87d0JUFDRqBH/+KXTtCqtW\nQagPm9ZPnz9N75m9CZAAPmn1CX1u6uM7MVnw4aIP+erEV4z8diSvrHyFse3Gcn+L+ykdVNrX0iwe\n8vvvEB9v/f/ewp0aAKq6CFiU4dzzLvtPA09ncd3nwOeXqdHi5NQpuOMOCAqCb76Br7/+lTFjWtCj\nh3EJlS1b8JpSNIUh84ew468dLB60mMA/A6kYXLHgheRA68qtGd1nNMtjlzNhxQRGfTeKV1e+yph2\nYxjRcoQ1BIUIOwDMu9iRwIWElBQYPNjUAGbPhjp1oGnTU8yYYRbF7tcPLl4seF0vrniR+b/NZ9Kt\nk7ip3k0FL8BNRIQb697IiqErWH7PchpWachjix+j7lt1eX3165y5cMbXEi1u4HBAuXKmBmy5fKwB\nKCRMnAgLFsDrr0OXLpfO33EHvPceLFoEw4cbH2lB8dVvXzF+xXgGhw/mkTaPFFzGl0nnOp1Zfs9y\nVgxdQZOqTXhiyRPUe7se/7fq/6wh8HMcDoiMNNNAWy4fawAKAV9+CRMmwNCh8PDDmcNHjIDnn4dP\nP4XnnisYTduObmPQl4NoVb0V/+n5H6QQDsnsWLsj3w/5npX3rqTZlc0Y8/0Y6rxVh3+t/Benz5/2\ntTxLBs6ehc2brfvHm1gD4OfExMCQIeat5/33sx/6Pn483H8/vPIKTJ6cv5pOJJ6g98zelAkqw7x+\n8wq9D71drXYsGbyEn4f9TKvqrRj7w1jqvFWHV356hVPnT/lansXJxo2QlGQNgDexBsCPOX7cuHjK\nloV58yA4h96LIsZA3H67qSXMyadOt8kpyUTNjWLvib3M7TeXmhUzDfoutLSt2ZZvB36L4z4H14dd\nz7PLnqXOm3V4ccWLnEw86Wt5xZ7UBuA2bXyroyjhVi+gguR8ynm2HtnqaxnpKBlYktwGzHmb5GS4\n+27Yuxeio6FGVpNvZKBECZg5E26+GQYNgqpVoWNH7+p6btlzfLf7Oz7o8QHta7X3buJ+QpuwNiwc\nsJD1B9YzccVEno9+ntcdr/Nom0d55PpHqBRcydcSvY6qsuH3vRxPPIWq+qVLz+GAevXM79riHfzO\nAOw9s5em7zf1tYxMdL2yKx07dSQwoGBan555BpYsgQ8/hBtucP+6MmXg66+hXTvo1Qt++gmaeulx\nzto6i3+u+ifDWwxnRKsR3knUj2lVvRULohbwy8FfmPjjRMavGM/rjtd5pM0jPHr9o1QuXdnXEvNM\niqYQcySGFXtXMH/TCn7680cuBB0BoKSjPLUr1qbhVXWoU7EOdSql3yqXruwTA+FwQKdOBZ5tkcbv\nDEC10tV4+663fS0jHY44B/9e/W/u/epePun9Sb4bgRkz4LXX4MEH4e9/9/z6kBBYvBjatoXbboOf\nf4ZatS5P0+ZDm7n3q3tpV7Md73R/5/ISK2Q0r9acL/t/yaZDm3jxxxd58ccXedPxJqPajOKx6x8j\npEyIryXmSnJKMlsOb2HF3hWs2LuCH/f+yLFzx0zgiVqUPNiVW6++gZ17/mLvyb/YVTGWuGqxaKUf\nSdT07SDlSpajTqU61K5YO5NxqFOpDiGlQ7xuIOLiYP9+6//3Nn5nAMqXKE/fRn19LSMdfRv15cTB\nE3y85WOSNZmpd0ylRED+PLpffoH77oP27eHNN/OeTu3a8N130KEDdOsGK1eaBTTywl9n/6L3zN5U\nLl2ZOf3mUDKwZN6FFWIiropgbr+5/Hr4V1788UVe+ekV3lrzFiNbj+SJG56gSpkqvpaYRlJKEhsP\nbmRFrCnwV/65kpPnTTtGjdL1KL23N6zqRMUTnRgzvA4jJ0CFCmaOm0aNOjNjBkydan6PgWVP0OH2\nWNp0jaXKNbHEJcSy9+ReYk/EsmrfKjP9hwtlg8oaA1GpdpY1iCplqnhsIOwAsPzB7wyAvzKo9iCu\nrnc1zyx7hhRN4bM+n3ndCBw9ahp9Q0JMI27Jyyxnw8Nh/nxjAHr1gqVLobSHHXaSUpLo979+HEo4\nxE/3/sRV5a66PFFFgKZXNmX2XbOJORLDiz++yL9W/Yt31r7DP1r/g9E3jKZq2YJ3Ul9IvsD6A+vT\nCvxV+1aRcCEBgIYhDenfuD9XXehE9Kcd+fGbMEJC4NXR8NBDUL58+rSqVoVHHjHbr7/C1KmV+Pzz\nCKJnRhASYqYiefYeaNnSdD44kXiCvSeMQUjbTprPn/f9nMlAlAkqk2YMsqpFhJYJzWQgHA4oVQqa\nNcvXx1jssAbAA57u8DSBAYE89f1TpGgK0/823WtG4OJFM5r3yBHjt7/ySq8kS5cu8NlnpkE5KsoY\nlhIeSB69xEyh8GnvT2ldo7V3RBUkW7dSff580ygSFOTVpBtXbczMvjN5odMLvPTTS/x79b+ZvG4y\nD7Z6kCdveJIry3npS8yCxKRE1u5fm1bg/7zvZ84lnTO6QhszJHwInep0omPtjuz65SomTIAPfzBz\nRqW6F92ZzbhpU5g0Cf75T9MmNW0a/Pe/8O67ZjTukCEwaFAlmtWoRLOrsi6dUw1Eaq3BdVu9bzXH\nE4+ni1+6ROl0BiL5WDIrYg9S/8baHE2sTbWgagRI8e7AqKocPnM47bn+efLPPKVjDYCHjGk3hkAJ\nZPTS0aRoCl/87QuCAi+/YHniCdPbZ9o0aOXRhK65068fHDpk3uhGjsx5PIErUzdN5a01b/FIm0e4\nJ+Ie74oqCL79Fvr1o0FCAqxdaxpXatf2ejbXhV7H9L9N5/mOz/PyTy/zhuMN3lv3Hg+0eoAnb3iS\nauWrXXYeZy+eZfW+1Wk+/DVxaziffB5BCL8ynL+3+Dud6nSiQ60OhJY1MwNGR0PUSPNZtaopyB94\nIG9zRpUoAd27m+3ECTMdydSpMHas6bBw881wzz2mBlumTPprKwVXotJV2RuIk4knMxmH1GNHnMMY\niKb/BSDsDQgKCKJmxZpptYfaFWtTu1LttM+wCmGF3k2ZlJLE/lP72Xtyb1ohn/bp3D+ffP6y87EG\nIA88ccMTBEgAjy95nBRNYcadMy7rB/fJJ/DOO/DYY2a+n/xg1Cg4cAD+9S/TpXTcuJzjr92/lhHf\njODGujcy6dZJ+SMqP/nPf4x/o2lTdnTpQsOPPoKICPOw77gjX7JsWKUh0/pMY1zHcbz808u8veZt\n3l//PsNbDOep9k9RvXx1t9NKuJDAqj9XpRX46/av42LKRQIkgBbVWjAyciSdaneifa32XFH6irTr\nVGHZMjNy/Mcf4aqr4I03zDQhGQvmvFKpkklv+HDYtcu8tEybBgMHGnfSXXcZY9Chg3svGhWDKxIe\nHE74leFZhr/1/o88Or4yY1/dS82m6QvC73Z/x8GEg+niC0L18tUvGYUMBqJ2xdqULemDmRNdOHfx\nHH+e/DPLgn3vyb3sP7WfZE2/2E3VslWpXbE24VeGc3uD2zPd1xXjr8gmt+yxBiCPPNb2MQIkgEcX\nP0r/Of2Z1XdWnozAmjXmrezmm03VPD959VU4eNBMG1Gtmhk5nBWHEg7xt1l/o1r5aszqOyvfGrzz\nhZQUePpp8zC7d4eZMzm4YQMNH3oI+veHPn3MSLn/+z/jVM4H6ofU59M7PmVcx3G88tMrTF43mf9s\n+A/3t7ifse3HElYhLNM1JxNPsvLPlWkF/oYDG0jWZEoElKBV9VY83vZxOtXuRLta7ahQqkKm61Xh\n++/NnFErV0L16vDWW6YXmaftPh7da3148cVLBmfqVFM7mDLFrFMxZIjZ6tXLex57fqsGR+rzj1ua\nUDOLcYfnk86z79S+LN+UHXEO/rftfySlJKW7JqR0SI4G4nK7urq6vbIq4I+cOZIufqAEUqNCDWpX\nrE3H2h0z6apVsVa+jLjPdUWwgqawrQj27tp3efjbh+nVsBez+872aNWpgweNu6dUKbPOaYgnvQlV\niV6xwuNViS5eNKOFly41DcS3354+/ELyBbpM7cIvB39h9X2rs622Z4dPV0o6d868ev7vf8bJ/fbb\nUKLEJU3nzxufxZtvQosWMGsWXJP/q5f9cfwPXvnpFT7d/CkBEsB9ze+jNa2pfHXltAJ/06FNpGgK\nJQNLElkjkk61O9GpdiduqHlDjm+rqsY3P2ECrF5tandPP216kuU0cjw7vPH9nTljRq5PmwY//GA0\nduhgDMFdd0FFD2cLv+WWw2zbdiVxce7VKDKSnJLMwYSDORbIZy+eTXdN2aCyORqINY411GhUI9v0\nMk4hElwimFoVa2WbXo0KNS77RSsvK4JZA+AmOf0x3lv3Hg8teoieDXoy5645bhmB8+dNA+3mzeaP\nG5517TdrYmKgd2/iq1QhZMECj4dGJiSYvGNizB+0bdtLYSO+HsGHGz9k5p0z6d+kv0fpgg8NwNGj\nZpkoh8O83T/+eFppkUnTggVmZr2kJOMqiooqEImxJ2L558p/MuWXKVxMMXN3B5cIpm1YW1Pg1+lE\nmxpt3HrTUzVNHBMnmlpkzZqm4B827PIqNt7+/vbtg88/NzWDHTuMUerTx9jpm292b1bPGjXO0aZN\naebN85qsdKgq8eficzQQaWMmsqFiqYo5GoyqZavm++C5vBgAVNWvtgYNGqg/snz58hzDP1j3gTIe\n7T69u567eC7HuCkpqvffrwqq//ufh0K+/161YkXV0FBNKllS9aqrVJct8zAR1cOHVa++WrVyZdXt\n29Pfw9ilYz1OL5XcnlO+sGOHuZngYNU5c9zTtHevart25ku4/37VM2fyX2dq1if26qPTH9Wf9v6k\niRcTPbo2JUV1wQLVVq2M9Nq1Vf/zH9VEz5LJlvz6/lJSVB0O1QcfVL3iCqO9WjXVJ59U3bo1++uO\nHDFx//WvfJHlNqfPn9ath7fqwp0L9b217+moz0fpgt8W6OZDm/XEuRO+FecEs0KjR+Wte5GgG7AD\n2A2MzSJ8KHAU2OTc7ncJuwfY5dzuyS2vwmoAVFU/XP+hMh7t9nm3HI3Ae++ZJ//MMx6K+OQT1RIl\nVBs3Vt27V9d+9JFqw4aqAQGq48erJiV5lNzu3apVq5pC5MsNP2mJiSX0ts9v06Rkz9JxpcANwI8/\nGisWGqq6erVnmi5eNF+CiHmmOZVEXsbT55SSojp/vmqLFua3U6eO6n//q3r+vG915YXERGOnb79d\nNTDQ3E/Llqpvv6169Gj6uF9/bcJXrMh3WR7hkxedXMgXA4BZB/h3oB5QEtgMNMoQZyjwbhbXVgb2\nOD+vcO5fkVN+hdkAqKp+tOEjlfGit352q569cDZT+IoVpgzv0cOD8jolRfW558zXdfPNqidOXNJ0\n+rTq4MEmrEsX1QMH3EzUsH69aukr92mJsVX16jfr6/Fzxz26PiMF+seYPl21ZEljBH//Pe+aFi82\nlrB0adWPPzbPO59x9zklJ6vOnavarJn5iq++WnXKFNULF3yry1scPqz6xhuqERHm/oKCVO+4Q3Xe\nPGPcnn1WNSAgRRMSClRWrhQVA+DOaIpIYLeq7lHVC8BMoLebHqauwFJVPaaqx4GlztpEkeW+Fvfx\nca+PWfr7UnrN7JWucWnfPujb1/SImD7dzVWNzp83fUNfesm07C1alL4VrVw509r2ySfGGdysmWkV\ndJNG4eeoOboPSXKOyku+orQUgpkuVc3CBwMHmrkBfv758rqZ3HqraYy54QbzjAcNgtO+XRAmJcUM\n2mveHO680yyGMnUq/PYb3Huv18e0+YyqVeHRR82UE5s3m+7Kq1fD3/5mejJNmQJXX53gk/WuCwUn\nT5oH99VXebo810ZgEekLdFPV+53Hg4E2qjrSJc5Q4FWMG2gn8Jiq7hOR0UCwqr7kjDcOOKeqkzLk\nMRwYDhAaGtpy9uzZebqZ/CQhIYFy7gyddPLdoe94bcdrRFSK4JUmryBJZXj44ebs31+a99/fSK1a\nZ3NNo8SpUzQZN45KW7aw5777+HPgwHTdIDJqKhMbS+MJEyizdy9/DhhA7L33ojlYGVXl1R2vsvTw\nUvpefIc5L4+kc+cjjBu3jYA8DrT09Dl5iiQl0eCNN6i2aBGHb76Z3558Es1lzgy3NSUnU2vGDOp+\n8gnnqldn2/PPk1C/vpeUu6cpORlWrAjls8/qEBtblpo1zzJ48F5uvPEIgYH532Ejv78/d0hOFtat\nu4LFi69i1aoq9O69h4ceivOppowU1HMqkZBA8KFDBB86RKlDhwg+fDjtOPjQIYISEtLiCni/ERjo\nC3zkcjyYDO4eIAQo5dwfASxz7o8GnnOJNw4YnVN+hd0F5Mpnmz/TgAkB2vmTztp/UIKKmAY8t/j9\nd+PaKFlS9Ysv3Nd05sylFub27VX37cs2izdWv6GMRydET1BV1ddeM5eNGpV3L0i+Vo1PnFC95RYj\nctw4t0V6rGnFCtUaNcyzf+edfHEJZdSUlGS+5uuuM7d37bXGw+Vhs47XdfmaxETVH35Y7mMVmfHa\nczp+XPWXX1S//NL4wh55RLV3b+Pzq1jR/Bhct7JlTXtVjx6qDz2k+n//Z3qSrF2bJxeQOx1P9wOu\nwy/CnOdcjUi8y+FHQOqQpv1A5wzXRruRZ5FgUPggAiSAQfMGoyW689yEhdx+uxtvDQ6Hmb0tOdmM\n7unQwf1My5Qxk7V06WIWC46IML6DHj3SRfthzw+MXjKaPtf24bmOZiHh0aPNaOE33zT9yceM8eRu\n85k//zT38Ntvxt01dGj+5dWxI2zadGkR5mXL4OOP4QrPR1rmRlKSWcTnpZdMN8nGjc1x37524XMw\nXVrzWhv1Oapm3ozY2Oy3UxmWHC1b1oygq1PH/O9r1zb7qVtISN4GQ2SDOwZgHVBfROpiCvS7gQGu\nEUSkmqqmjsfuBWx37i8GXhGR1H/OrcDTl626EBF6aADMDUD+NogVYd05fX4h5UuVz/6CuXOND7pG\nDePvb9AgbxkPGGBGmfXrBz17mtL9lVcgKIg/jv9Bvzn9uLbKtUy9Y2raxFoi8O9/mwFqTz1lRgvn\n19QUHrFhg7mHs2fNHNc33ZT/eVapYsYLvPmmeRjNm5uS2UvzEScnC9OmmYJ/1y5o0sSMoL3zzkJc\n4BU3VM26rdkV7nv3Zi7gy5W7VJh37Ji+cK9Tx8zZXoCL7eRqAFQ1SURGYgrzQGCKqsaIyERMlWMB\nMEpEegFJwDFMryBU9ZiIvIgxIgATVTXHERVl9+6FFSuKxNI/e/aY2Qca17ibJ28PYNjCAdw2/TYW\nDVyUeTi/qil9x4wxhcxXX5mpGy+HBg1MbeKJJ8xMYD/9xJnPpnDHD1GkaArz756fyRgFBJgKw5Ej\nZlBR1arQtevlybgsvvnGPMQqVUxtqHHjgss7IMAMKGvf3kyn2qGDMaJPPJHnUvriRTMw6rnnIjlw\nwLTZz51rpifyWcF/6jFc4JgAABabSURBVJQZPT1vHhFxcZ4P1c1nIk6e9DtNrfbvN4MPM3YWKF/+\nUmHeuXPmAv6KKwq0gM8Nt8Yeq+oiYFGGc8+77D9NNm/2qjoFmOK2ouRk8+DuuceM6LzcQtBHJCSY\ngalgply4+up+lCkdQNTcKLp93o3vBn13yQgkJZnuD++/b8bKT53qvQlcgoNh8mTo3Bm9/z7uHR/B\n1gbJLBq4iGsqZz0NQqlS8OWXxgbfeaeZTdLbM5S6xeTJ5rm0aGHWubzKR2sRREbCxo1mYp0xY2D5\ncvMdefDbvHjRdNZ6+WX44w+oXz+JL780nj6fFPzJyWYY+NSp5ss+dw6uuQYtX96z+cILAA0M9DtN\niVddRbmePS8V7KmuGj8r4HPF00aD/N4a1q9vBucEBZkhg//9r+kM7WM8afRJSVG9804zPmvJkvRh\n87bN0xITS+j1H11vRhCePq3avbtp4BkzxqN79bQh6pX5o5Xx6Gs3YBqbchk+euCAGSQWGqq6a1f+\naMqSpCTVxx4zz6RXL73cTuBea7BLSTGj+EqVUq1eXTU6OtdLzp83I3Vr19a0AU8LFqguW+YlTZ4S\nE2N+Z9WrG0FXXGGG5zocqikpftcIrOp/DdOq/qmJ/BoJXJBbWi+gmBjVjh2NxLZtVTdv9u7T8hBP\nvvCXXjKyJ03KOnz+9vkaNDFIIydH6PHWTcxwyA8+yFdNC3cuVBkvGjW7n6Y8+sil0mj37hyv++03\n1ZAQMwDp0CHvasqSM2dU+/S51B3JC91gvP5n3bRJtUGDHEdgJyaqvv++aq1a5lYiI1UXLrzUoahA\nC5C//jK9mVLnjwgMVO3Z0/QeyfAS4I8Fm9XkHkXCANSo0UgvXnTeUUqK6qefqlapYn60o0ebN2Yf\n4O4X/vXXZmaBgQNz7j244Lu3NGgc2uqBAD22YFa+atrx1w6t+GpFbf5Bcz1zwTnnzfz5qpUqqVao\noDp7do7Xr15tBsm2bJn747+sP8ahQ6akFFF98828p+NNTdmRcQT2/v2qqnrunOq776qGhZmg669X\n/fbbzL+FfC9Azp8333GfPqY2DWa47euv52jJ/bFgs5rco0gYAGip1aqZWmpMjPPO/vpL9e9/N3Jr\n1jR9ZgtguL4r7nzh27eb8rRFC9WzmWeBuMR336mWL69ft62sJScGaYv/tND4s/H5oulk4km99t1r\ntcprVTT2eGz6wNhYU0KBcQOcy37+oq+/Njb41ltznn8mz3+MbdvMBDelS5uCy4vk65/1009Vy5TR\ns1Vq6tsPbkvzrLRrZ9x/2f1M80VTSoqZ2+Phh81LE6heeaXq44+7XYP2x4LNanKPImEAqldvpL16\nXZokqnVr1cmTVePjVXXVKtWmTU3A7bebAqyAyO0LP3HCjNsKDf3/9s49Oqr62uPfTUJISMJbKC1Y\nQBF5CIIvrl5R8Wqplpei+MBSq9VWY9FyveJ1tRcFRbyCPKRVUZQiykIQdEUWghgBiyJEeaqg8n4m\nMRBAJAmZ7/1jn0kmyUxykszknOvsz1pZOTNzHt85Z85vn9/+7d/emmgyIi++qF+uZ09y716+t/09\nNhrXiOe/cD7zfsiLqqaSQAkHvjGQCY8nMGtnhHWLijQlI6CTT7Zti7i/V17R1UaMiDxUUasbIytL\neyNt2pCffVbz7avdfVbU9xnk5EnyuTEH2TbxMAHy8nY7+MHS4mqfT6Kqaf9+ncXXvbteoKQk8qab\nyMxMlnWn3eHHhs00ueMnYQCCYwCHDmlvtWfPst/0sGFk5uJiFj/9LNm4sf5NnBi7zFghVHXBS0p0\nYl5iYhVZC0tKyDFj9MsMGEAWFJR+tPSbpWw0rhF7/aMXc3/IjbCDmmkiyb9++FdiLDh97fTqd5aZ\nqc7+1FTy9dcjrjZuHEvHq2ujqRL//Ke6KLp1I3furNm2LonFzXriBDlpktosgLyy32lmDZzE0jGr\nah5O6qzp5EmdOvyrX+lYRPC4L7xA5ufXerd+bNhMkzt+UgYglC++0KCV0F7t6D8UcHP/P+sb3btr\nWuAYUtUFf+wxlTFjRoQVfvyRHD5cV7r33rBPZe9/+z6TxyfzvL+fx5wTOXXWtPDLhcRY8M7FdzLg\n1l22d6+mjwDIu+4KmyM/EFBvERDeTe/6xggEdAAVIPv31ynxMSKaN+vx4/qw3bp1mfRyRn/ePDI9\nXXs0ixZFV1MgQK5erak+mjRRAWeeqT/AKnpuNcGPDZtpcsdP1gAEKSzUe2rIEH3aBsgLzjrCac3/\nxly0JH//+8oJxaNEpAv+1ltl7WXYdjY3t6zwyDPPVDl2sfy75UwZn8Ief+/BwycO11rT5sObmfpk\nKi+ZeUmNC46wuFgblGCO/NKBmDJOn9axRRFt79xoKkdhIfnb3+o5+d3vop/UvgLRuFmPHSMnTCh7\nCLnmGm2Lw/LttzpiHoxkChNuWyNNO3aosezUiaX5YEaO1EJAUQ6R9mPDZprc8ZM3AKHk5OgTaO/e\n+i0aNijmDbKQ76bfxqIXZ9XLjbFpk96LfftGCKnfvp08+2yNG68m0ibIih0rmDI+hd1mdOOh41XH\nXYbT9P3J79lpaif+7Nmfcf+x/a6OGZZly8py5M+aVclwnTypnYWkpPIFyaq9MY4c0agZgHziCV/l\n3g9HQQH55JNacybovVuzxsWGp06RDz6oG/XpU2kiRbWaCgp00CUYCi2i3Y3Zs2MaCefHhs00uSOu\nDEAoGzbovKEzWhQTIFvjEB/6+TxuXLC9xvuKRMULnpdHduyoZe32h2tnV69Wn3qrVjp4XZNj7cxi\n4ycbs+vzXXnw+EHXmopLinntnGuZNC6Ja/a4aaWq4cCBssb6jjsqNTz5+dpJaNJEr0E4TeXYuVPT\nXTZsSM6ZU3d9LqnNzXr0qNqnYPnC667TuVI15p13dCfp6eWyuobVdPq0Gt7bb1fDC5CdO+vEkioj\nC6KHHxs20+SOuDUAQYqKyHcXl/CGPjvZEIUa+tx6H6dMPMUcd271iIRe8OJiLcyVlBShUXjzTf2w\nc2f3U2grsHLXSqY+mcpznz+XB46Fr/JV8Uf48LKHibHgzOyZtTpmWE6fJh9/XAcau3SpFE64Z49m\nTm7bVtv3iDfG2rXao2je3NUM2mhSk5v1yBH1tjRrxtJgs3Xr6iggTP3hcpq+/JJ85BE9kYAe/I9/\n1AkYPgx3rm9Mkzvi3gCEkvt1Hqf1fZ0XYB0BMjGhhEOG6BhCbVzOoRf8L3/RMzdrVoWVAgF1FAdz\n8efVLKyzIqt2rWLaU2k8Z/o5Yd05oZrmbppLjAXvy7yvTseMSFaWtvKNGmmkSUjDtGWLtlldupCL\nF4dxjC9apE+0HTuWVaCvR9zcrN9/ryUGgmOrgweT2dlRFFGh/nD29Ok6Y+yii1g6O/f669VVWMV8\njFjjx4bNNLnDDEA4Vq/mprOGcDT+l20a5RNQr8yoURpd5JbgBZ8zR89aRkaFFYqKygqx3Hpr1G7i\nj3d/zPSn0tl5WmfuK9gXVlP2gWwmj09mv1f7seh0DENiDx/WmWCARjWFhLKuWqW2oXHjYvburYPE\nDz1ETh2axXcwiBt63M6j39SxG1ZLqrpZ8/J0zDs9Xb/WDTfU7HdRY4L1h4MFPnr1qnZ2bn3ix4bN\nNLnDDEAkiorIiRNZnJzGzEZDOazn10xKChDQeQaTJ2vbVhVZWVlcv55MTiavuKLC1IOCgrKG8bHH\noj4AvWbPGqY/lc6zpp7FPUf3lNN0+MRhnvncmWw/ub2ryKE6U1KivZyEBE0QFPKYvHIlOXjwPl53\nHdmtW4CNE09VKmjUrJlmJBgyRMdIp0zRib8bNpTWuo864W7W3FydlpGWprqGDavHdFMHD3L7Aw+U\nDZz4CD82bKbJHWYAqmPnTnXqAvy+62WcMfq70h54YqJ+tHBheBfRwoUfs107DbsuN56wZ4/OTk5M\n1KiNGPHJ3k/YZEITdpraibuP6oDg8hXLecWrVzB5fDLX718fs2OHZfVqTXiTlEROm1bqEsrKytJZ\nUgMHMgAw509/42eflvCtt7R63f33q6eje3eNoApnIHr1UhfMqFFaJW/RIn0qr+1UgdCbNSdHJ7Gl\npqo3ZvhwcvPmup+OumjyE37UZZrcYQbALYsXa04hZ1Buy8dH+PDD6uIGNHgnI0PTqgQCahB69jzC\nlBTy889D9pOdrRs1aVI573MMWLtvLZtOaMqOUzpy15FdHPrSUGIs+PrGyDN3Y0penmaVBNTnk5/P\nfy1YoDHwDRpUMTNOCQT0SXzdOpYaiIwM3WWPHuENRNOm5Q3E5Mnk22/rdcnPDz9mmpWVxUOHyNGj\ndfJ4gwbkbbeFneJQb/ixASH9qcs0ucMMQE04flyziyYk6KDAa6+xuCjAJUvIm2/WB1tAG6IBA3S5\nXG32zExtodq31wkB9cS6/evY7OlmbDGxBTEWHP3+6Ho7dlgCAc2JkJhIdujAH9u00fOSmRmVXefl\nqSFesEDTa4caiKD7JvSvSRN16w0apHOwJk8mhw3bw5QUbfhHjNAU117jxwaE9Kcu0+SOmBkAAAMA\nbAPwLYAxVax3IwACuNB53RDAbACboXWCH63uWPVmAIJs3Eheeqmein79Sh8L8/M1n/sll+hHt9wS\nEoc9Y4a2Jn36RJgEEFuyD2SzxcQWvGjqRSwuqVmyr5jx6afkL3/JUy1bVugmxY5AQKN3srPVdTdp\nkibCHDhQvXLBgd0GDQIcOTJq2RKigh8bENKfukyTO2JiAKB1gL8D0AlAEoCNALqFWS8dwCoAn4YY\ngNsAzHOWGwPYBaBDVcerdwNA6sDmzJkao56YSD76aLk8OIcOORWcSkrUjwDoY6hHtQlI8njhcX7w\n4QeeHT8sP/7IVUuWeK2ilKCBWLToY6+lVMKPDQjpT12myR21MQBuqpFeDOBbkjtIFgGYB2BwmPXG\nAZgI4FRoxUkAqSKSCCAFQBGAYy6OWb80aADcfTewbRswYgQwYYIWH3/vPQBAmzZAQuEprdc7aRKQ\nkaGFftPSPJOclpSGBEnw7PhhSU5GSbRqGUcBEaBFC6BZs2KvpRiGLxE1HFWsIDIMwACSdzuv7wBw\nCcmMkHX6AHiM5I0i8hGA/yS5XkQaApgD4GpoD+Ahki+FOcY9AO4BgDPOOOOC+fPnR+XL1ZamGzbg\nnClTkLp7N3Ivvxy7R4zAWZMno9n27fjuvvuw78YbfVH4+cSJE0jz0AiFwzS5w4+aAH/qMk3uuOqq\nq7JJXlijjarrIgAYBuDlkNd3AHg+5HUDAB/Bce04y0EX0GUA5kLHAlpDxxE6VXU8T1xA4Sgs1Hh3\nJyfL6UaNNNzER/ixG2qa3OFHTaQ/dZkmdyBGLqD9ANqHvG7nvBckHUAPAB+JyC4AfQG8KyIXQscA\nlpIsJpkD4F8AamahvCIpCRgzBti6FcjIwIbnngOGDvValWEYRtRwYwDWAegsIh1FJAnALQDeDX5I\nsoBkK5IdSHaADgIPIrkewB4A/QFARFKhxuHrKH+H2NKxIzB9Oo537eq1EsMwjKhSrQEgeRpABoD3\noaGc80luFZEnRGRQNZvPAJAmIluhhuRVkpvqKtowDMOoO4luViK5BMCSCu/9LcK6V4YsnwBwUx30\nGYZhGDHCjQvIMAzD+AliBsAwDCNOMQNgGIYRp5gBMAzDiFPMABiGYcQpZgAMwzDilGpzAdU3InIc\nmjLCb7QCkOe1iAqYJneYJvf4UZdpckcXkuk12cDVPIB6ZhtrmtCoHhCR9X7TZZrcYZrc40ddpskd\nIrK+ptuYC8gwDCNOMQNgGIYRp/jRAFSqF+AT/KjLNLnDNLnHj7pMkztqrMl3g8CGYRhG/eDHHoBh\nGIZRD5gBMAzDiFN8YwBEZJaI5IjIFq+1BBGR9iKSJSJfishWERnlA03JIvKZiGx0ND3utaYgIpIg\nIl+ISKbXWoKIyC4R2SwiG2oTJhcLRKSZiCwQka9F5CsR+TeP9XRxzk/w75iIPOilJkfXQ85vfIuI\nvCkiyT7QNMrRs9XLcxSuvRSRFiKyXES+cf43r24/vjEAAF4DMMBrERU4DWA0yW7Qamb3i0g3jzUV\nAuhPsheA8wEMEJG+HmsKMgpaNMhvXEXyfB/FbU+Flko9F0AveHzOSG5zzs/5AC4AcBLAIi81icgv\nAPwZWl+8B4AEaDVCLzX1APAHABdDr9tvRORsj+S8hsrt5RgAK0h2BrDCeV0lvjEAJFcByPdaRygk\nD5L83Fk+Dr1Rf+GxJjqFdgCgofPn+Ui+iLQDcD2Al73W4mdEpCmAfgBeAQCSRSSPequqHFcD+I7k\nbq+FQCeqpohIIoDGAA54rKcrgLUkTzqVElcCuMELIRHay8EAZjvLswEMqW4/vjEAfkdEOgDoDWCt\nt0pKXS0bAOQAWE7Sc00ApgD4LwABr4VUgACWiUi2iNzjtRgAHQHkAnjVcZe97NTL9gu3AHjTaxEk\n9wN4FlpX/CCAApLLvFWFLQAuF5GWItIYwHUA2nusKZQ2JA86y4cAtKluAzMALhCRNAALATxI8pjX\nekiWON31dgAudrqmniEivwGQQzLbSx0R+HeSfQD8GurC6+exnkQAfQD8g2RvAD/ARVe9PhCRJACD\nALzlAy3NoU+0HQH8HECqiIzwUhPJrwBMBLAMwFIAGwCUeKkpEtT4/mo9A2YAqkFEGkIb/7kk3/Za\nTyiO6yAL3o+dXAZgkIjsAjAPQH8Red1bSYrzJAmSOVC/9sXeKsI+APtCem0LoAbBD/wawOckD3st\nBMB/ANhJMpdkMYC3AVzqsSaQfIXkBST7ATgCYLvXmkI4LCJtAcD5n1PdBmYAqkBEBOqr/YrkZK/1\nAICInCEizZzlFADXAPjaS00kHyXZjmQHqAvhQ5KePq0BgIikikh6cBnAtdBuvGeQPARgr4h0cd66\nGsCXHkoK5Vb4wP3jsAdAXxFp7NyHV8MHAQYi0tr5fybU//+Gt4rK8S6Akc7ySADvVLeBb7KBisib\nAK4E0EpE9gH4H5KveKsKlwG4A8Bmx+cOAP9NcomHmtoCmC0iCVADPp+kb8IufUYbAIu0/UAigDdI\nLvVWEgDgAQBzHZfLDgB3eqwnaCCvAXCv11oAgORaEVkA4HNoNN4X8Ef6hYUi0hJAMYD7vRrAD9de\nAngawHwRuQvAbgA3V7sfSwVhGIYRn5gLyDAMI04xA2AYhhGnmAEwDMOIU8wAGIZhxClmAAzDMOIU\nMwBGXCIiJRUyYEZtNq6IdPBTVlvDiIRv5gEYRj3zo5NOwzDiFusBGEYITv2AZ5waAp8F0/06T/Uf\nisgmEVnhzASFiLQRkUVOfYaNIhJMV5AgIjOdvPHLnFnbhuErzAAY8UpKBRfQ8JDPCkieB+B5aJZT\nAJgOYDbJngDmApjmvD8NwEqnPkMfAFud9zsDmEGyO4CjAG6M8fcxjBpjM4GNuERETpBMC/P+LmjB\nnR1OIsBDJFuKSB6AtiSLnfcPkmwlIrkA2pEsDNlHB2ia7s7O60cANCQ5PvbfzDDcYz0Aw6gMIyzX\nhMKQ5RLYeJvhQ8wAGEZlhof8/8RZXoOykoS3A1jtLK8A8CegtFBP0/oSaRh1xZ5KjHglJSTDK6A1\neoOhoM1FZBP0Kf5W570HoFW8HoZW9Apm8BwF4CUnA2MJ1BgchGH8P8DGAAwjBGcM4EKSeV5rMYxY\nYy4gwzCMOMV6AIZhGHGK9QAMwzDiFDMAhmEYcYoZAMMwjDjFDIBhGEacYgbAMAwjTvk/xARpNqP2\nODoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "su=pd.read_csv('/content/drive/My Drive/Assessment/modelsummary.csv')\n",
    "su.columns=['Epoch','time','loss','accuracy','val_loss','val_acc','Model']\n",
    "\n",
    "df = su.pivot(index='Epoch', columns='Model', values='val_acc')\n",
    "\n",
    "df.plot(title=\"Validation Accuracy in 10 Epochs\",grid=True,color=['red', 'blue', 'green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pMkRIp29uCvz"
   },
   "source": [
    "## Error/Loss\n",
    "\n",
    "In this criterion, we will be looking only at VGG16 and MobileNet since InceptionV3 yielded *nan* as its validation loss function across 10 epochs.\n",
    "\n",
    "* VGG16 (**7.9489**)\n",
    "* MobileNet (**0.9489**)\n",
    "\n",
    "As seen from the graph below, it is clear that MobileNet has the lower validation loss in almost all 10 epochs. It experienced its greatest decline in loss from the 5th to 7th epoch.\n",
    "\n",
    "**Winner: MobileNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "Cks0FIjzc3Al",
    "outputId": "9559c63b-b4ce-4c2a-fb0a-4ea399b94c84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8a639d24e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEWCAYAAAB/tMx4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTJj6/wcs8jFLCsA/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = su.pivot(index='Epoch', columns='Model', values='val_loss')\n",
    "\n",
    "df.plot(title=\"Validation Loss in 10 Epochs\",grid=True,color=['red', 'blue', 'green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mPb4rVdxW8V"
   },
   "source": [
    "## Run Time\n",
    "\n",
    "After 10 epochs, the run time of each model are as follows:\n",
    "* VGG16 (**125 minutes**)\n",
    "* InceptionV3 (**53 minutes**)\n",
    "* MobileNet (**24 minutes**)\n",
    "\n",
    "The average run time of an epoch in VGG16 is 12 minutes while an epoch in InceptionV3 takes an average of 5 minutes. MobileNet is a lightweight network. The average run time of an epoch in this network is 2 minutes. \n",
    "\n",
    "The massive difference in run time makes MobileNet the clear winner.\n",
    "\n",
    "**Winner: MobileNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "id": "9L8BeNezcU6g",
    "outputId": "19bf333b-2d49-4a94-afd2-dfa50e0c00a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8a63d3fcc0>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEWCAYAAACKSkfIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS/rGGBNBLOkbY0wE+f8BT3oRjIjqjNAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = su.pivot(index='Epoch', columns='Model', values='time')\n",
    "\n",
    "df.plot(title=\"Run Time in Seconds 10 Epochs\",grid=True,color=['red', 'blue', 'green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYH5Mcl_2F61"
   },
   "source": [
    "## Usability\n",
    "\n",
    "In terms of deployment, MobileNet has the clear advantage against the other two models.\n",
    "\n",
    "In only 24 minutes, we are able to train a model with 63% accuracy over 10 epochs with a validation loss of 0.9482. MobileNet in this case is a fast, accurate, and well-behaved model.\n",
    "\n",
    "Deployment of MobileNet will be more feasible and effective. Due to its compactness, it can be deployed through mobile phones or smaller gadgets.\n",
    "\n",
    "Looking beyond our current objective of classifying the boxes as either'good' or 'bad', we can expand MobileNet's usage to different variations of the problem at hand. Its lightweight architecture enables it to be trained on top of another algorithm with less computational cost and better accuracy. An example would be creating a mobile application that assesses the condition of delivery goods based on images.\n",
    "\n",
    "**Winner: MobileNet**\n",
    "\n",
    "\n",
    "## Champion Model: MobileNet\n",
    "\n",
    "MobileNet is at a clear advantage against its competitors in this scenario. VGG16 and InceptionV3 may have better stability and accuracy once fine-tuned, but it would take much more time to iterate. \n",
    "\n",
    "To see further how well MobileNet will perform, we ran our champion model over 100 epochs given the same set of parameters. It resulted to a model with **79.29%** validation accuracy, and a loss of **0.5793** under **4 hours** of training. We will be using this model to predict 'good' and 'bad' boxes in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Cr7blO7iDMG"
   },
   "source": [
    "## Recommendations\n",
    "\n",
    "Listed below are some possible improvements for this problem:\n",
    "*   Iterate on other models e.g. MobileNetV2, ShuffleNet, ResNet,DenseNet\n",
    "*  Allot more time to fine tune the model\n",
    "*   If possible, gather more data\n",
    "*   Add augmentated images into data \n",
    "*   Perform regularization in the network so that the model would learn better\n",
    "\n",
    "\n",
    "## References\n",
    "*   https://neurohive.io/en/popular-networks/vgg16/\n",
    "*   https://keras.io/applications/\n",
    "*   https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-   xception-keras/\n",
    "*   https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c\n",
    "*  https://machinethink.net/blog/mobilenet-v2/\n",
    "*  https://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/\n",
    "* https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d\n",
    "*   https://towardsdatascience.com/transfer-learning-using-mobilenet-and-keras-c75daf7ff299\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7CwvQuU5F7LY"
   },
   "source": [
    "# Training and Prediction Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgm_gNq0u9xC"
   },
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7383
    },
    "colab_type": "code",
    "id": "pDfvrudJgnm7",
    "outputId": "03a720ac-860b-4b44-b63c-df6e15f97ef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Build model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 2)           2050      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,230,914\n",
      "Trainable params: 3,209,026\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 225 images belonging to 2 classes.\n",
      "Found 148 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:81: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., verbose=2, shuffle=True, steps_per_epoch=30, epochs=100, validation_steps=70)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 210s - loss: 0.9368 - acc: 0.6750 - val_loss: 8.1742 - val_acc: 0.4929\n",
      "Epoch 2/100\n",
      " - 147s - loss: 0.9658 - acc: 0.6163 - val_loss: 8.2317 - val_acc: 0.4893\n",
      "Epoch 3/100\n",
      " - 144s - loss: 1.0807 - acc: 0.6000 - val_loss: 8.0015 - val_acc: 0.5036\n",
      "Epoch 4/100\n",
      " - 141s - loss: 0.8378 - acc: 0.7006 - val_loss: 4.9150 - val_acc: 0.4964\n",
      "Epoch 5/100\n",
      " - 143s - loss: 0.6370 - acc: 0.7583 - val_loss: 6.6668 - val_acc: 0.4893\n",
      "Epoch 6/100\n",
      " - 142s - loss: 0.6849 - acc: 0.7248 - val_loss: 1.0231 - val_acc: 0.5786\n",
      "Epoch 7/100\n",
      " - 143s - loss: 0.7311 - acc: 0.7333 - val_loss: 0.7293 - val_acc: 0.5607\n",
      "Epoch 8/100\n",
      " - 141s - loss: 0.8418 - acc: 0.5997 - val_loss: 5.6836 - val_acc: 0.5071\n",
      "Epoch 9/100\n",
      " - 143s - loss: 0.7768 - acc: 0.7500 - val_loss: 1.1119 - val_acc: 0.6107\n",
      "Epoch 10/100\n",
      " - 141s - loss: 0.6352 - acc: 0.7581 - val_loss: 1.6867 - val_acc: 0.4750\n",
      "Epoch 11/100\n",
      " - 144s - loss: 0.7636 - acc: 0.7417 - val_loss: 1.0287 - val_acc: 0.5714\n",
      "Epoch 12/100\n",
      " - 141s - loss: 0.7252 - acc: 0.7173 - val_loss: 0.9191 - val_acc: 0.5893\n",
      "Epoch 13/100\n",
      " - 142s - loss: 0.7640 - acc: 0.7250 - val_loss: 0.8152 - val_acc: 0.6179\n",
      "Epoch 14/100\n",
      " - 141s - loss: 0.6711 - acc: 0.7339 - val_loss: 0.5404 - val_acc: 0.7143\n",
      "Epoch 15/100\n",
      " - 142s - loss: 0.6140 - acc: 0.7833 - val_loss: 0.5355 - val_acc: 0.7357\n",
      "Epoch 16/100\n",
      " - 141s - loss: 0.9449 - acc: 0.6589 - val_loss: 0.7540 - val_acc: 0.5857\n",
      "Epoch 17/100\n",
      " - 142s - loss: 0.6401 - acc: 0.7250 - val_loss: 0.5607 - val_acc: 0.6893\n",
      "Epoch 18/100\n",
      " - 142s - loss: 0.7046 - acc: 0.7756 - val_loss: 0.8476 - val_acc: 0.6464\n",
      "Epoch 19/100\n",
      " - 142s - loss: 1.0902 - acc: 0.7256 - val_loss: 1.2512 - val_acc: 0.7214\n",
      "Epoch 20/100\n",
      " - 142s - loss: 0.9910 - acc: 0.7750 - val_loss: 1.1572 - val_acc: 0.5500\n",
      "Epoch 21/100\n",
      " - 141s - loss: 0.4099 - acc: 0.8249 - val_loss: 1.2079 - val_acc: 0.5286\n",
      "Epoch 22/100\n",
      " - 142s - loss: 0.4191 - acc: 0.8417 - val_loss: 1.6858 - val_acc: 0.5250\n",
      "Epoch 23/100\n",
      " - 140s - loss: 0.6650 - acc: 0.8082 - val_loss: 1.5783 - val_acc: 0.5143\n",
      "Epoch 24/100\n",
      " - 142s - loss: 0.8560 - acc: 0.7750 - val_loss: 0.4960 - val_acc: 0.7357\n",
      "Epoch 25/100\n",
      " - 141s - loss: 0.7600 - acc: 0.7339 - val_loss: 0.8592 - val_acc: 0.6929\n",
      "Epoch 26/100\n",
      " - 142s - loss: 0.8603 - acc: 0.7917 - val_loss: 0.8922 - val_acc: 0.6321\n",
      "Epoch 27/100\n",
      " - 141s - loss: 0.6329 - acc: 0.7415 - val_loss: 0.3881 - val_acc: 0.8071\n",
      "Epoch 28/100\n",
      " - 142s - loss: 0.6069 - acc: 0.7833 - val_loss: 0.6534 - val_acc: 0.7250\n",
      "Epoch 29/100\n",
      " - 140s - loss: 0.5158 - acc: 0.8582 - val_loss: 0.9348 - val_acc: 0.7214\n",
      "Epoch 30/100\n",
      " - 143s - loss: 0.5809 - acc: 0.8167 - val_loss: 0.6821 - val_acc: 0.7036\n",
      "Epoch 31/100\n",
      " - 141s - loss: 0.5833 - acc: 0.7832 - val_loss: 0.7302 - val_acc: 0.6786\n",
      "Epoch 32/100\n",
      " - 142s - loss: 0.5858 - acc: 0.8000 - val_loss: 0.9025 - val_acc: 0.7036\n",
      "Epoch 33/100\n",
      " - 141s - loss: 0.5933 - acc: 0.8082 - val_loss: 0.9731 - val_acc: 0.5500\n",
      "Epoch 34/100\n",
      " - 142s - loss: 0.5509 - acc: 0.7917 - val_loss: 1.2140 - val_acc: 0.5357\n",
      "Epoch 35/100\n",
      " - 142s - loss: 0.5916 - acc: 0.7665 - val_loss: 0.6575 - val_acc: 0.6929\n",
      "Epoch 36/100\n",
      " - 142s - loss: 0.7115 - acc: 0.7667 - val_loss: 1.0656 - val_acc: 0.5143\n",
      "Epoch 37/100\n",
      " - 141s - loss: 0.5353 - acc: 0.8415 - val_loss: 0.6653 - val_acc: 0.6893\n",
      "Epoch 38/100\n",
      " - 141s - loss: 0.3982 - acc: 0.8582 - val_loss: 0.6975 - val_acc: 0.7393\n",
      "Epoch 39/100\n",
      " - 142s - loss: 0.4985 - acc: 0.7833 - val_loss: 0.5171 - val_acc: 0.7036\n",
      "Epoch 40/100\n",
      " - 140s - loss: 0.4643 - acc: 0.8499 - val_loss: 1.1975 - val_acc: 0.4929\n",
      "Epoch 41/100\n",
      " - 143s - loss: 0.4597 - acc: 0.8583 - val_loss: 1.1304 - val_acc: 0.5929\n",
      "Epoch 42/100\n",
      " - 141s - loss: 0.4739 - acc: 0.8332 - val_loss: 0.8149 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      " - 143s - loss: 0.5192 - acc: 0.7750 - val_loss: 0.6578 - val_acc: 0.6786\n",
      "Epoch 44/100\n",
      " - 141s - loss: 0.3114 - acc: 0.9333 - val_loss: 1.9469 - val_acc: 0.5143\n",
      "Epoch 45/100\n",
      " - 142s - loss: 0.6419 - acc: 0.7833 - val_loss: 1.4159 - val_acc: 0.5786\n",
      "Epoch 46/100\n",
      " - 141s - loss: 0.5713 - acc: 0.8090 - val_loss: 2.7728 - val_acc: 0.5929\n",
      "Epoch 47/100\n",
      " - 142s - loss: 0.4280 - acc: 0.8583 - val_loss: 0.8712 - val_acc: 0.6393\n",
      "Epoch 48/100\n",
      " - 141s - loss: 0.4593 - acc: 0.8257 - val_loss: 0.7601 - val_acc: 0.6286\n",
      "Epoch 49/100\n",
      " - 142s - loss: 0.3494 - acc: 0.8583 - val_loss: 0.4485 - val_acc: 0.7536\n",
      "Epoch 50/100\n",
      " - 141s - loss: 0.5624 - acc: 0.8082 - val_loss: 0.6938 - val_acc: 0.6500\n",
      "Epoch 51/100\n",
      " - 142s - loss: 0.3095 - acc: 0.8667 - val_loss: 0.6731 - val_acc: 0.6143\n",
      "Epoch 52/100\n",
      " - 142s - loss: 0.5252 - acc: 0.8165 - val_loss: 0.9666 - val_acc: 0.6357\n",
      "Epoch 53/100\n",
      " - 142s - loss: 0.3789 - acc: 0.8583 - val_loss: 0.4849 - val_acc: 0.7536\n",
      "Epoch 54/100\n",
      " - 141s - loss: 0.3654 - acc: 0.8916 - val_loss: 0.4074 - val_acc: 0.8321\n",
      "Epoch 55/100\n",
      " - 142s - loss: 0.3594 - acc: 0.8750 - val_loss: 0.5242 - val_acc: 0.7429\n",
      "Epoch 56/100\n",
      " - 141s - loss: 0.4675 - acc: 0.8415 - val_loss: 0.4697 - val_acc: 0.7643\n",
      "Epoch 57/100\n",
      " - 141s - loss: 0.3338 - acc: 0.8999 - val_loss: 0.6751 - val_acc: 0.5750\n",
      "Epoch 58/100\n",
      " - 143s - loss: 0.3215 - acc: 0.9083 - val_loss: 0.4857 - val_acc: 0.8179\n",
      "Epoch 59/100\n",
      " - 141s - loss: 0.3608 - acc: 0.8415 - val_loss: 0.9626 - val_acc: 0.5643\n",
      "Epoch 60/100\n",
      " - 143s - loss: 0.3281 - acc: 0.8833 - val_loss: 1.4488 - val_acc: 0.4893\n",
      "Epoch 61/100\n",
      " - 141s - loss: 0.5186 - acc: 0.8332 - val_loss: 2.1494 - val_acc: 0.5286\n",
      "Epoch 62/100\n",
      " - 143s - loss: 0.6033 - acc: 0.8667 - val_loss: 0.7021 - val_acc: 0.6286\n",
      "Epoch 63/100\n",
      " - 141s - loss: 0.5864 - acc: 0.7756 - val_loss: 0.6118 - val_acc: 0.7786\n",
      "Epoch 64/100\n",
      " - 142s - loss: 0.6488 - acc: 0.8250 - val_loss: 0.7890 - val_acc: 0.7143\n",
      "Epoch 65/100\n",
      " - 141s - loss: 0.3603 - acc: 0.8499 - val_loss: 0.4063 - val_acc: 0.8143\n",
      "Epoch 66/100\n",
      " - 143s - loss: 0.3041 - acc: 0.8917 - val_loss: 1.7093 - val_acc: 0.4929\n",
      "Epoch 67/100\n",
      " - 141s - loss: 0.5722 - acc: 0.7915 - val_loss: 0.5925 - val_acc: 0.6250\n",
      "Epoch 68/100\n",
      " - 143s - loss: 0.2918 - acc: 0.8917 - val_loss: 0.5474 - val_acc: 0.6786\n",
      "Epoch 69/100\n",
      " - 141s - loss: 0.1956 - acc: 0.9333 - val_loss: 0.4278 - val_acc: 0.7893\n",
      "Epoch 70/100\n",
      " - 142s - loss: 0.3765 - acc: 0.8667 - val_loss: 1.4411 - val_acc: 0.5179\n",
      "Epoch 71/100\n",
      " - 142s - loss: 0.2845 - acc: 0.9083 - val_loss: 0.8409 - val_acc: 0.6714\n",
      "Epoch 72/100\n",
      " - 142s - loss: 0.3267 - acc: 0.8667 - val_loss: 0.3497 - val_acc: 0.8286\n",
      "Epoch 73/100\n",
      " - 142s - loss: 0.4683 - acc: 0.8090 - val_loss: 1.2645 - val_acc: 0.6214\n",
      "Epoch 74/100\n",
      " - 142s - loss: 0.3512 - acc: 0.8500 - val_loss: 0.4684 - val_acc: 0.8250\n",
      "Epoch 75/100\n",
      " - 142s - loss: 0.3586 - acc: 0.8916 - val_loss: 0.7202 - val_acc: 0.6750\n",
      "Epoch 76/100\n",
      " - 142s - loss: 0.2287 - acc: 0.9166 - val_loss: 0.6579 - val_acc: 0.7464\n",
      "Epoch 77/100\n",
      " - 144s - loss: 0.2413 - acc: 0.9333 - val_loss: 0.9122 - val_acc: 0.7321\n",
      "Epoch 78/100\n",
      " - 141s - loss: 0.2587 - acc: 0.8999 - val_loss: 0.5579 - val_acc: 0.7607\n",
      "Epoch 79/100\n",
      " - 143s - loss: 0.2404 - acc: 0.9250 - val_loss: 0.6544 - val_acc: 0.7107\n",
      "Epoch 80/100\n",
      " - 141s - loss: 0.3100 - acc: 0.8832 - val_loss: 1.3267 - val_acc: 0.5929\n",
      "Epoch 81/100\n",
      " - 142s - loss: 0.3415 - acc: 0.8750 - val_loss: 0.5069 - val_acc: 0.7714\n",
      "Epoch 82/100\n",
      " - 141s - loss: 0.2637 - acc: 0.9083 - val_loss: 0.8823 - val_acc: 0.7143\n",
      "Epoch 83/100\n",
      " - 143s - loss: 0.2108 - acc: 0.9417 - val_loss: 1.4335 - val_acc: 0.5893\n",
      "Epoch 84/100\n",
      " - 141s - loss: 0.2147 - acc: 0.9249 - val_loss: 1.2903 - val_acc: 0.5143\n",
      "Epoch 85/100\n",
      " - 143s - loss: 0.2717 - acc: 0.9250 - val_loss: 0.8106 - val_acc: 0.7393\n",
      "Epoch 86/100\n",
      " - 141s - loss: 0.2684 - acc: 0.8999 - val_loss: 0.4446 - val_acc: 0.7929\n",
      "Epoch 87/100\n",
      " - 143s - loss: 0.2788 - acc: 0.9083 - val_loss: 0.7721 - val_acc: 0.7286\n",
      "Epoch 88/100\n",
      " - 141s - loss: 0.3575 - acc: 0.8674 - val_loss: 0.9400 - val_acc: 0.6429\n",
      "Epoch 89/100\n",
      " - 142s - loss: 0.1927 - acc: 0.9417 - val_loss: 0.8081 - val_acc: 0.7357\n",
      "Epoch 90/100\n",
      " - 142s - loss: 0.1582 - acc: 0.9508 - val_loss: 1.0269 - val_acc: 0.6893\n",
      "Epoch 91/100\n",
      " - 142s - loss: 0.3377 - acc: 0.8750 - val_loss: 2.1678 - val_acc: 0.6000\n",
      "Epoch 92/100\n",
      " - 142s - loss: 0.2294 - acc: 0.8999 - val_loss: 1.6710 - val_acc: 0.5393\n",
      "Epoch 93/100\n",
      " - 143s - loss: 0.1974 - acc: 0.9333 - val_loss: 1.7712 - val_acc: 0.6036\n",
      "Epoch 94/100\n",
      " - 141s - loss: 0.2392 - acc: 0.8999 - val_loss: 1.9279 - val_acc: 0.5714\n",
      "Epoch 95/100\n",
      " - 140s - loss: 0.2473 - acc: 0.9416 - val_loss: 1.2113 - val_acc: 0.6643\n",
      "Epoch 96/100\n",
      " - 142s - loss: 0.2977 - acc: 0.8667 - val_loss: 1.3710 - val_acc: 0.6607\n",
      "Epoch 97/100\n",
      " - 140s - loss: 0.3358 - acc: 0.8832 - val_loss: 1.1458 - val_acc: 0.6821\n",
      "Epoch 98/100\n",
      " - 142s - loss: 0.4067 - acc: 0.8750 - val_loss: 1.7194 - val_acc: 0.6000\n",
      "Epoch 99/100\n",
      " - 141s - loss: 0.5256 - acc: 0.8415 - val_loss: 1.8698 - val_acc: 0.6357\n",
      "Epoch 100/100\n",
      " - 143s - loss: 0.1989 - acc: 0.9250 - val_loss: 0.5793 - val_acc: 0.7929\n",
      "14254.24017071724\n"
     ]
    }
   ],
   "source": [
    "#mobile NET\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNet\n",
    "import numpy as np\n",
    "import time\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(45)\n",
    "    nb_class = 2\n",
    "    width, height = 224,224\n",
    "\n",
    "    sn=keras.applications.mobilenet.MobileNet(classes=2,weights=None)\n",
    "    print('Build model')\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=0.0002, momentum=0.9, nesterov=True)\n",
    "    sn.compile(\n",
    "        optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(sn.summary())\n",
    "\n",
    "    # Training\n",
    "    train_data_dir = '/content/drive/My Drive/Assessment/boxes/train'\n",
    "    validation_data_dir = '/content/drive/My Drive/Assessment/boxes/test'\n",
    "    nb_train_samples=120\n",
    "    nb_validation_samples=70\n",
    "    nb_epoch=100\n",
    "\n",
    "    #   Generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(width, height),\n",
    "            batch_size=4,\n",
    "            class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            target_size=(width, height),\n",
    "            batch_size=4,\n",
    "            class_mode='categorical')\n",
    "                                        \n",
    "    start=time.time()\n",
    "    sn.fit_generator(\n",
    "            train_generator,\n",
    "            samples_per_epoch=nb_train_samples,\n",
    "            nb_epoch=nb_epoch,\n",
    "            validation_data=validation_generator,\n",
    "            nb_val_samples=nb_validation_samples, \n",
    "            verbose=2,\n",
    "            shuffle=True)\n",
    "    end=time.time()\n",
    "    sn.save_weights('/content/drive/My Drive/Assessment/boxes/weights_mobilenet.h5')\n",
    "   \n",
    "    print(end-start)\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-iGaxE9Be7g"
   },
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "IgoTPm9z9DGw",
    "outputId": "27940ebf-6bd8-4fca-b210-4a851ef9f16b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3024, 4032, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=0.0002, momentum=0.9, nesterov=True)\n",
    "model =keras.applications.mobilenet.MobileNet(classes=2,weights=None)\n",
    "\n",
    "model.load_weights('/content/drive/My Drive/Assessment/boxes/weights_mobilenet.h5')\n",
    "model.compile(\n",
    "        optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'],)\n",
    "\n",
    "\n",
    "##bad image\n",
    "#img=cv2.imread(\"/content/drive/My Drive/Assessment/test/NG/IMG_6785.JPG\")\n",
    "##good image\n",
    "img=cv2.imread(\"/content/drive/My Drive/Assessment/test/OK/IMG_6764.JPG\")\n",
    "img=img/255.\n",
    "print(img.shape)\n",
    "img=cv2.resize(img,(224,224),3)\n",
    "img=np.expand_dims(img,axis=0)\n",
    "print(img.shape)\n",
    "\n",
    "result=model.predict(img)\n",
    "\n",
    "#0= Not Good 1=Good\n",
    "np.argmax(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1mPb4rVdxW8V"
   ],
   "name": "ImageClassification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
